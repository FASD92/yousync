"""
STT ì²˜ë¦¬ ëª¨ë“ˆ (stt_processor.py)

ê¸°ëŠ¥:
- ì‚¬ìš©ì ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (Whisper ì‚¬ìš©)
- MFA í˜¸í™˜ .lab íŒŒì¼ ìƒì„±
- ìë™ ì–¸ì–´ ê°ì§€

ì…ë ¥: ì „ì²˜ë¦¬ëœ ì‚¬ìš©ì ìŒì„± íŒŒì¼
ì¶œë ¥: .lab í…ìŠ¤íŠ¸ íŒŒì¼ (MFA í˜•ì‹)
"""

import whisper
import sys
import os
from pathlib import Path
import json
import re

# ì „ì—­ ëª¨ë¸ ìºì‹œ
_whisper_model = None

def load_whisper_model(model_size: str = "base.en"):
    """
    Whisper ëª¨ë¸ ë¡œë“œ (ì „ì—­ ìºì‹œ ì‚¬ìš©)
    
    Args:
        model_size: ëª¨ë¸ í¬ê¸° ("tiny", "base", "small", "medium", "large")
    
    Returns:
        ë¡œë“œëœ Whisper ëª¨ë¸
    """
    global _whisper_model
    
    if _whisper_model is None:
        print(f"ğŸ¤– Whisper {model_size} ëª¨ë¸ ë¡œë“œ ì¤‘...")
        _whisper_model = whisper.load_model(model_size)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    return _whisper_model

def transcribe_user_audio(audio_path: str, output_lab_path: str = None, 
                         model_size: str = "base.en") -> dict:
    """
    ì‚¬ìš©ì ìŒì„±ì„ STTë¡œ ë³€í™˜í•˜ì—¬ .lab íŒŒì¼ ìƒì„±
    
    Args:
        audio_path: ì „ì²˜ë¦¬ëœ ìŒì„± íŒŒì¼ ê²½ë¡œ
        output_lab_path: .lab íŒŒì¼ ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        model_size: Whisper ëª¨ë¸ í¬ê¸°
    
    Returns:
        STT ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (í…ìŠ¤íŠ¸, ì„¸ê·¸ë¨¼íŠ¸ ë“±)
    """
    print(f"ğŸ¯ STT ì²˜ë¦¬ ì‹œì‘: {audio_path}")
    
    try:
        # ëª¨ë¸ ë¡œë“œ
        model = load_whisper_model(model_size)
        
        # Whisperë¡œ ìŒì„± ì¸ì‹
        print("ğŸ¤ ìŒì„± ì¸ì‹ ì¤‘...")
        result = model.transcribe(
            audio_path,
            language="en",  # ì˜ì–´ ê³ ì •
            word_timestamps=True,  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
            verbose=False
        )
        
        # ê²°ê³¼ ì •ë¦¬
        transcription_result = {
            "text": result["text"].strip(),
            "language": result["language"],
            "segments": result["segments"]
        }
        
        print(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {transcription_result['text']}")
        
        # .lab íŒŒì¼ ìƒì„±
        if output_lab_path is None:
            audio_name = Path(audio_path).stem
            output_lab_path = f"../shared_data/user/lab/{audio_name}.lab"
        
        lab_path = create_lab_file(transcription_result["text"], output_lab_path)
        transcription_result["lab_file"] = str(lab_path)
        
        print(f"âœ… STT ì²˜ë¦¬ ì™„ë£Œ: {lab_path}")
        return transcription_result
        
    except Exception as e:
        print(f"âŒ STT ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise

def create_lab_file(text: str, output_path: str) -> str:
    """
    í…ìŠ¤íŠ¸ë¥¼ MFA í˜¸í™˜ .lab íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        text: ë³€í™˜ëœ í…ìŠ¤íŠ¸
        output_path: .lab íŒŒì¼ ì €ì¥ ê²½ë¡œ
    
    Returns:
        ìƒì„±ëœ .lab íŒŒì¼ ê²½ë¡œ
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    # í…ìŠ¤íŠ¸ ì •ë¦¬ (MFA í˜¸í™˜)
    cleaned_text = clean_text_for_mfa(text)
    
    # .lab íŒŒì¼ ì €ì¥ (ë‹¨ìˆœ í…ìŠ¤íŠ¸ í˜•ì‹)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(cleaned_text)
    
    print(f"ğŸ“„ .lab íŒŒì¼ ìƒì„±: {output_path}")
    return str(output_path)

def clean_text_for_mfa(text: str) -> str:
    """
    MFA í˜¸í™˜ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì •ë¦¬
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
    
    Returns:
        ì •ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    # ê¸°ë³¸ ì •ë¦¬
    text = text.strip()
    
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text)
    
    return text

def extract_segments_info(transcription_result: dict) -> list:
    """
    STT ê²°ê³¼ì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì¶”ì¶œ
    
    Args:
        transcription_result: transcribe_user_audio ê²°ê³¼
    
    Returns:
        ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    segments = []
    
    for segment in transcription_result.get("segments", []):
        segments.append({
            "start": segment.get("start", 0),
            "end": segment.get("end", 0),
            "text": segment.get("text", "").strip()
        })
    
    return segments

def get_detailed_word_timestamps(transcription_result: dict) -> list:
    """
    STT ê²°ê³¼ì—ì„œ ë‹¨ì–´ë³„ ìƒì„¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
    
    Args:
        transcription_result: transcribe_user_audio ê²°ê³¼
    
    Returns:
        ë‹¨ì–´ë³„ ìƒì„¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    detailed_segments = []
    
    for segment in transcription_result.get("segments", []):
        # word-level timestampsê°€ ìˆëŠ” ê²½ìš° í™œìš©
        if "words" in segment and segment["words"]:
            for word in segment["words"]:
                if word.get("start") is not None and word.get("end") is not None:
                    detailed_segments.append({
                        "start": word.get("start", 0),
                        "end": word.get("end", 0),
                        "text": word.get("word", "").strip()
                    })
        else:
            # word-levelì´ ì—†ìœ¼ë©´ segment-level ì‚¬ìš©
            detailed_segments.append({
                "start": segment.get("start", 0),
                "end": segment.get("end", 0),
                "text": segment.get("text", "").strip()
            })
    
    return detailed_segments

def get_optimized_segments_for_pitch(transcription_result: dict, min_duration: float = 0.5) -> list:
    """
    í”¼ì¹˜ ë¶„ì„ì— ìµœì í™”ëœ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
    
    Args:
        transcription_result: transcribe_user_audio ê²°ê³¼
        min_duration: ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)
    
    Returns:
        í”¼ì¹˜ ë¶„ì„ìš© ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    segments = []
    
    for segment in transcription_result.get("segments", []):
        start = segment.get("start", 0)
        end = segment.get("end", 0)
        duration = end - start
        
        # ë„ˆë¬´ ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ëŠ” í”¼ì¹˜ ë¶„ì„ì— ë¶€ì í•©í•˜ë¯€ë¡œ í•„í„°ë§
        if duration >= min_duration:
            segments.append({
                "start": start,
                "end": end,
                "text": segment.get("text", "").strip(),
                "duration": duration
            })
    
    print(f"ğŸ“Š í”¼ì¹˜ ë¶„ì„ìš© ì„¸ê·¸ë¨¼íŠ¸: {len(segments)}ê°œ (ìµœì†Œ {min_duration}ì´ˆ ì´ìƒ)")
    
    return segments

def save_transcription_result(result: dict, output_path: str) -> str:
    """
    STT ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        result: transcribe_user_audio ê²°ê³¼
        output_path: JSON íŒŒì¼ ì €ì¥ ê²½ë¡œ
    
    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f" STT ê²°ê³¼ ì €ì¥: {output_path}")
    return output_path
