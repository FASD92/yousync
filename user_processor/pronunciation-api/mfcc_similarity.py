import librosa
import numpy as np
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity

# ë¡œê·¸ ì¶œë ¥ ì„¤ì • (í•„ìš”ì‹œ í™œì„±í™”)
DEBUG_MODE = True

def debug_print(message):
    """ë””ë²„ê·¸ ë©”ì‹œì§€ ì¶œë ¥ (DEBUG_MODEê°€ Trueì¼ ë•Œë§Œ)"""
    if DEBUG_MODE:
        print(f"[MFCC_DEBUG] {message}")

# ì—°ì† ì„ í˜• ë³´ê°„ì„ ìœ„í•œ ì ìˆ˜ ë§¤í•‘ í¬ì¸íŠ¸
# ë°ì´í„°ì…‹ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„¤ì •:
# - ì •ë‹µ ìŒì„±: â‰ƒ0.45 (90-100ì )
# - íŒ€ì›(ì •ìƒ ë°œìŒ): â‰ƒ0.10 (70ì )  
# - ë‹¨ì–´ 2ê°œ ëˆ„ë½: â‰ƒ0.08 (50ì )
# - ì•¡ì„¼íŠ¸ ì—†ì´ ë°œìŒ: â‰ƒ0.09 (60ì )
# - ì¹¨ë¬µ: â‰ƒ0.02 (0ì )
# 0.08~0.10 êµ¬ê°„ì—ì„œ ì„¸ë°€í•œ ì ìˆ˜ êµ¬ë¶„ì´ ì¤‘ìš”í•¨
sim_points = [0.00, 0.02, 0.05, 0.08, 0.09, 0.10, 0.30, 0.40, 0.53, 1.00]
score_points = [0.0,  0.0,  40.0,  50.0,  60.0,  70.0,   80.0,   90.0,   100.0, 100.0]

def continuous_score(similarity: float) -> float:
    """
    ì—°ì† ì„ í˜• ë³´ê°„ì„ ì‚¬ìš©í•œ 0~100ì  ë§¤í•‘
    
    ê¸°ì¡´ if-elif êµ¬ì¡°ë¥¼ ëŒ€ì²´:
    - 0.4~0.53: 90~100ì  (ì •ë‹µ ìŒì„± ìˆ˜ì¤€)
    - 0.3~0.39: 80~89ì  (ìš°ìˆ˜í•œ ë°œìŒ)
    - 0.1~0.29: 70~79ì  (ì •ìƒ ë°œìŒ)
    - 0.09~0.099: 60~69ì  (ì•¡ì„¼íŠ¸ ì—†ëŠ” ë°œìŒ)
    - 0.08~0.089: 50~59ì  (ë‹¨ì–´ ëˆ„ë½)
    - 0.05~0.079: 40~49ì  (ë¶€ì¡±í•œ ë°œìŒ)
    - 0.02 ì´í•˜: 0ì  (ì¹¨ë¬µ/ë¬´ìŒì„±)
    """
    return float(np.interp(similarity, sim_points, score_points))

def _apply_cmvn(mfcc):
    """
    MFCCì— CMVN(Cepstral Mean and Variance Normalization) ì ìš©
    
    Parameters:
    -----------
    mfcc : ndarray
        (ì‹œê°„, íŠ¹ì„±) í˜•íƒœì˜ MFCC í–‰ë ¬
        
    Returns:
    --------
    ndarray
        CMVNì´ ì ìš©ëœ MFCC í–‰ë ¬
    """
    if mfcc.shape[0] == 0:
        return mfcc
    
    # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
    mean = np.mean(mfcc, axis=0)
    std = np.std(mfcc, axis=0) + 1e-9  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    
    # ì •ê·œí™” ì ìš©
    normalized = (mfcc - mean) / std
    
    return normalized

def cmvn_with_c0_clipping(mfcc):
    """
    CMVN + C0 ì ì‘ì  í´ë¦¬í•‘ ì •ê·œí™”
    mfcc: (N_frames, 13)
    """
    if mfcc.shape[0] == 0:
        return mfcc
    
    # 1) C1â€“C12 CMVN (ìŠ¤í™íŠ¸ëŸ¼ í˜•íƒœ ì •ë³´)
    rest = mfcc[:, 1:]                   # (N,12)
    rest_mean = rest.mean(axis=0)        # (12,)
    rest_std = rest.std(axis=0) + 1e-9   # (12,) - 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    rest_norm = (rest - rest_mean) / rest_std  # (N,12)

    # 2) C0 í´ë¦¬í•‘ (ì—ë„ˆì§€ ì •ë³´)
    c0 = mfcc[:, 0]                      # (N,)
    c0_min = np.percentile(c0, 5)
    c0_max = np.percentile(c0, 95)

    if c0_max - c0_min < 1e-6:
        c0_norm = np.full_like(c0, 0.5)
    else:
        c0_clipped = np.clip(c0, c0_min, c0_max)
        c0_norm = (c0_clipped - c0_min) / (c0_max - c0_min)

    # 3) ë‹¤ì‹œ í•©ì¹˜ê¸°
    mfcc_norm = np.concatenate(
        [c0_norm[:, None], rest_norm],
        axis=1
    )  # (N,13)
    return mfcc_norm

def _add_delta_features(mfcc):
    """
    MFCCì— ë¸íƒ€ ë° ë¸íƒ€-ë¸íƒ€ íŠ¹ì„± ì¶”ê°€
    
    Parameters:
    -----------
    mfcc : ndarray
        (ì‹œê°„, íŠ¹ì„±) í˜•íƒœì˜ MFCC í–‰ë ¬
        
    Returns:
    --------
    ndarray
        ë¸íƒ€ ë° ë¸íƒ€-ë¸íƒ€ íŠ¹ì„±ì´ ì¶”ê°€ëœ MFCC í–‰ë ¬
    """
    if mfcc.shape[0] == 0:
        return np.zeros((0, 39))
    
    # í”„ë ˆì„ ìˆ˜ì— ë”°ë¼ ì²˜ë¦¬ ë°©ì‹ ê²°ì •
    n_frames = mfcc.shape[0]
    
    # ë§¤ìš° ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ (5í”„ë ˆì„ ë¯¸ë§Œ)
    if n_frames < 5:
        debug_print(f"ë§¤ìš° ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ê°ì§€ - í”„ë ˆì„ ìˆ˜: {n_frames}, íŒ¨ë”© ì ìš©")
        # íŒ¨ë”© ì¶”ê°€ (ì–‘ìª½ì— ì›ë³¸ ë°ì´í„° ë°˜ë³µ)
        pad_size = max(0, 5 - n_frames)
        padded_mfcc = np.pad(mfcc, ((pad_size, pad_size), (0, 0)), mode='edge')
        
        # íŒ¨ë”©ëœ ë°ì´í„°ë¡œ ë¸íƒ€ ê³„ì‚° (ìµœì†Œ ìœˆë„ìš° í¬ê¸° ì‚¬ìš©)
        delta_mfcc = librosa.feature.delta(padded_mfcc.T, width=3).T
        delta2_mfcc = librosa.feature.delta(padded_mfcc.T, order=2, width=3).T
        
        # íŒ¨ë”© ì œê±°í•˜ê³  ì›ë˜ í¬ê¸°ë¡œ ë³µì›
        if pad_size > 0:
            delta_mfcc = delta_mfcc[pad_size:pad_size+n_frames]
            delta2_mfcc = delta2_mfcc[pad_size:pad_size+n_frames]
    
    # ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ (5~9í”„ë ˆì„)
    elif n_frames < 9:
        debug_print(f"ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ê°ì§€ - í”„ë ˆì„ ìˆ˜: {n_frames}")
        # ìœˆë„ìš° í¬ê¸°ë¥¼ í”„ë ˆì„ ìˆ˜ì— ë§ê²Œ ì¡°ì • (í™€ìˆ˜ì—¬ì•¼ í•¨)
        width = n_frames if n_frames % 2 == 1 else n_frames - 1
        width = max(3, width)  # ìµœì†Œ 3 í”„ë ˆì„ í•„ìš”
        
        delta_mfcc = librosa.feature.delta(mfcc.T, width=width).T
        delta2_mfcc = librosa.feature.delta(mfcc.T, order=2, width=width).T
    
    # ì¼ë°˜ì ì¸ ê²½ìš° (9í”„ë ˆì„ ì´ìƒ)
    else:
        # ê¸°ë³¸ ìœˆë„ìš° í¬ê¸° ì‚¬ìš©
        delta_mfcc = librosa.feature.delta(mfcc.T).T
        delta2_mfcc = librosa.feature.delta(mfcc.T, order=2).T
    
    # íŠ¹ì„± ê²°í•©
    mfcc_with_delta = np.concatenate([mfcc, delta_mfcc, delta2_mfcc], axis=1)
    
    return mfcc_with_delta

def _pad_reference_mfcc(mfcc, target_length):
    """
    MFCCì— íŒ¨ë”©ì„ ì¶”ê°€í•˜ì—¬ ëª©í‘œ ê¸¸ì´ì— ë§ì¶¤
    
    Parameters:
    -----------
    mfcc : ndarray
        MFCC ë²¡í„° (N, D) í˜•íƒœ
    target_length : int
        ëª©í‘œ í”„ë ˆì„ ìˆ˜
        
    Returns:
    --------
    ndarray
        íŒ¨ë”©ëœ MFCC ë²¡í„° (target_length, D) í˜•íƒœ
    """
    if len(mfcc) >= target_length:
        return mfcc  # ì´ë¯¸ ì¶©ë¶„íˆ ê¸¸ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        
    # í•„ìš”í•œ íŒ¨ë”© í¬ê¸° ê³„ì‚°
    pad_size = target_length - len(mfcc)
    
    # ì—£ì§€ íŒ¨ë”© (ê°€ì¥ìë¦¬ ê°’ ë°˜ë³µ)
    padded_mfcc = np.pad(mfcc, ((0, pad_size), (0, 0)), mode='edge')
    
    debug_print(f"MFCC íŒ¨ë”© ì ìš©: {len(mfcc)} â†’ {len(padded_mfcc)} í”„ë ˆì„")
    return padded_mfcc



def frame_wise_euclidean_similarity(ref_mfcc, user_mfcc):
    """
    í”„ë ˆì„ë³„ ìœ í´ë¦¬ë””ì–¸ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
    í‘œì¤€í¸ì°¨ ê¸°ë°˜ ë‹¨ì–´ ëˆ„ë½ ê°ì§€ ë¡œì§ í¬í•¨
    
    Parameters:
    -----------
    ref_mfcc : ndarray
        ê¸°ì¤€ MFCC íŠ¹ì„±
    user_mfcc : ndarray
        ì‚¬ìš©ì MFCC íŠ¹ì„±
        
    Returns:
    --------
    float
        ìœ ì‚¬ë„ ì ìˆ˜ (0~1)
    """
    # ë¹ˆ ë°°ì—´ ì²´í¬
    if ref_mfcc.shape[0] == 0 or user_mfcc.shape[0] == 0:
        debug_print("ë¹ˆ MFCC ë°°ì—´ ê°ì§€ë¨")
        return 0.0
    
    # ìµœì†Œ í”„ë ˆì„ ìˆ˜ ì„¤ì • (ì´ ê°’ ë¯¸ë§Œì¸ ê²½ìš° 0ì  ì²˜ë¦¬)
    MIN_FRAMES = 5
    
    # í”„ë ˆì„ ìˆ˜ê°€ ìµœì†Œ ê¸°ì¤€ ë¯¸ë§Œì¸ ê²½ìš° 0ì  ì²˜ë¦¬
    if ref_mfcc.shape[0] < MIN_FRAMES or user_mfcc.shape[0] < MIN_FRAMES:
        debug_print(f"í”„ë ˆì„ ìˆ˜ ë¶€ì¡± - ref: {ref_mfcc.shape[0]}, user: {user_mfcc.shape[0]} < ìµœì†Œ ê¸°ì¤€: {MIN_FRAMES}")
        return 0.0
    
    try:
        # í‘œì¤€í¸ì°¨ ê¸°ë°˜ ë‹¨ì–´ ëˆ„ë½ ê°ì§€
        ref_std = _calculate_std_deviation(ref_mfcc)
        user_std = _calculate_std_deviation(user_mfcc)
        
        # í‘œì¤€í¸ì°¨ ë¹„ìœ¨ ê³„ì‚° (ì‚¬ìš©ì/ê¸°ì¤€)
        std_ratio = user_std / ref_std if ref_std > 0 else 0.0
        debug_print(f"í‘œì¤€í¸ì°¨ ë¹„êµ - ê¸°ì¤€: {ref_std:.4f}, ì‚¬ìš©ì: {user_std:.4f}, ë¹„ìœ¨: {std_ratio:.4f}")
        
        # í‘œì¤€í¸ì°¨ ì°¨ì´ê°€ í¬ë©´ ë‹¨ì–´ ëˆ„ë½ ê°€ëŠ¥ì„± ë†’ìŒ
        # ì‚¬ìš©ì í‘œì¤€í¸ì°¨ê°€ ê¸°ì¤€ í‘œì¤€í¸ì°¨ì˜ 50% ë¯¸ë§Œì´ë©´ ë‹¨ì–´ ëˆ„ë½ìœ¼ë¡œ ê°„ì£¼
        STD_THRESHOLD = 0.5
        if std_ratio < STD_THRESHOLD:
            debug_print(f"í‘œì¤€í¸ì°¨ ë¹„ìœ¨ì´ ë„ˆë¬´ ë‚®ìŒ ({std_ratio:.4f} < {STD_THRESHOLD}) - ë‹¨ì–´ ëˆ„ë½ ê°€ëŠ¥ì„± ë†’ìŒ")
            
            # í‘œì¤€í¸ì°¨ ë¹„ìœ¨ì— ë”°ë¼ íŒ¨ë„í‹° ì ìš© (ë¹„ìœ¨ì´ ë‚®ì„ìˆ˜ë¡ ë” í° íŒ¨ë„í‹°)
            penalty_factor = 1.0 - (std_ratio / STD_THRESHOLD)
            similarity = 0.05 * (1.0 - penalty_factor)  # ìµœëŒ€ 0.05ì˜ ìœ ì‚¬ë„
            
            debug_print(f"í‘œì¤€í¸ì°¨ ê¸°ë°˜ ë‹¨ì–´ ëˆ„ë½ ê°ì§€ - ìœ ì‚¬ë„: {similarity:.4f}")
            return similarity
        
        # ë¸íƒ€ íŠ¹ì„±ì´ ì—†ëŠ” ê²½ìš° ì¶”ê°€
        if ref_mfcc.shape[1] == 13:
            ref_mfcc = _add_delta_features(ref_mfcc)
            debug_print(f"ê¸°ì¤€ MFCCì— ë¸íƒ€ íŠ¹ì„± ì¶”ê°€ - shape: {ref_mfcc.shape}")
            
        if user_mfcc.shape[1] == 13:
            user_mfcc = _add_delta_features(user_mfcc)
            debug_print(f"ì‚¬ìš©ì MFCCì— ë¸íƒ€ íŠ¹ì„± ì¶”ê°€ - shape: {user_mfcc.shape}")
        
        # CMVN ì ìš©
        ref_norm = _apply_cmvn(ref_mfcc)
        user_norm = _apply_cmvn(user_mfcc)
        
        # ê°€ì¤‘ì¹˜ ì ìš© (MFCC, ë¸íƒ€, ë¸íƒ€-ë¸íƒ€ì— ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ ë¶€ì—¬)
        dimension_weights = [1.5, 0.8, 0.3]  # MFCC, ë¸íƒ€, ë¸íƒ€-ë¸íƒ€ ê°€ì¤‘ì¹˜
        d = ref_norm.shape[1] // 3
        w = np.concatenate([
            np.full(d, dimension_weights[0]),
            np.full(d, dimension_weights[1]),
            np.full(d, dimension_weights[2])
        ])
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        ref_norm = ref_norm * w
        user_norm = user_norm * w
        
        # í”„ë ˆì„ ìˆ˜ê°€ ë‹¤ë¥¸ ê²½ìš° íŒ¨ë”© ì ìš©
        if len(ref_norm) != len(user_norm):
            debug_print(f"í”„ë ˆì„ ìˆ˜ ë¶ˆì¼ì¹˜ - ref: {len(ref_norm)}, user: {len(user_norm)}")
            
            # ë” ì§§ì€ ìª½ì— íŒ¨ë”© ì ìš©
            if len(ref_norm) > len(user_norm):
                user_norm = _pad_reference_mfcc(user_norm, len(ref_norm))
            else:
                ref_norm = _pad_reference_mfcc(ref_norm, len(user_norm))
        
        # ìœ í´ë¦¬ë””ì–¸ ê±°ë¦¬ ê³„ì‚°
        frame_distances = np.sqrt(np.sum((ref_norm - user_norm) ** 2, axis=1))
        mean_distance = np.mean(frame_distances)
        
        # ìœ ì‚¬ë„ë¡œ ë³€í™˜
        similarity = 1.0 / (1.0 + mean_distance)
        
        # í‘œì¤€í¸ì°¨ ë¹„ìœ¨ì— ë”°ë¥¸ ìœ ì‚¬ë„ ì¡°ì •
        # í‘œì¤€í¸ì°¨ ë¹„ìœ¨ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ íŒ¨ë„í‹° ì—†ìŒ, 0.5ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìµœëŒ€ 30% íŒ¨ë„í‹°
        if std_ratio < 1.0:
            std_penalty = (1.0 - std_ratio) * 0.3  # ìµœëŒ€ 30% íŒ¨ë„í‹°
            similarity = similarity * (1.0 - std_penalty)
            debug_print(f"í‘œì¤€í¸ì°¨ ë¹„ìœ¨ì— ë”°ë¥¸ íŒ¨ë„í‹° ì ìš©: {std_penalty:.4f}, ì¡°ì •ëœ ìœ ì‚¬ë„: {similarity:.4f}")
        
        debug_print(f"ìœ ì‚¬ë„ ê³„ì‚° ì™„ë£Œ: {similarity:.4f}")
        return similarity
        
    except Exception as e:
        print(f"[MFCC_ERROR] ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return 0.0

def extract_mfcc_from_audio(audio_path: str, sr: int = 16000) -> tuple[np.ndarray, np.ndarray]:
    """
    ìŒì„±ì—ì„œ mfccë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    ê°œì„ ëœ ë²„ì „: 25ms ìœˆë„ìš°, 10ms í™‰ í¬ê¸° ì‚¬ìš©
    """
    debug_print(f"extract_mfcc_from_audio ì‹œì‘ - íŒŒì¼: {audio_path}")
    
    # ì˜¤ë””ì˜¤ ë¡œë“œ
    y, _ = librosa.load(audio_path, sr=sr)
    
    # MFCC ì¶”ì¶œ (25ms ìœˆë„ìš°, 10ms í™‰ í¬ê¸°)
    n_fft = 512  # FFT window size
    win_length = int(0.025 * sr)  # 25ms
    hop_length = int(0.010 * sr)  # 10ms
    
    mfcc = librosa.feature.mfcc(
        y=y, sr=sr, n_mfcc=13,
        n_fft=n_fft,
        win_length=win_length,
        hop_length=hop_length
    )
    mfcc = mfcc.T  # (N,13) í˜•íƒœë¡œ ë³€í™˜. ì¦‰, í”„ë ˆì„ë§ˆë‹¤ 13ì°¨ì› ë²¡í„°ê°€ í•˜ë‚˜ì”© ì¡´ì¬í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜

    duration = librosa.get_duration(y=y, sr=sr) # ì „ì²´ ì˜¤ë””ì˜¤ ê¸¸ì´
    n_frames = mfcc.shape[0]    #   í”„ë ˆì„ ìˆ˜ n_framesë§Œí¼
    frame_times = np.linspace(0, duration, num=n_frames)    # 0ì´ˆ~durationì´ˆë¥¼ ê· ë“±í•˜ê²Œ ë‚˜ëˆ”. ì¦‰, ê° MFCC ë²¡í„°ê°€ 'ëª‡ ì´ˆì¯¤ì— í•´ë‹¹í•˜ëŠ” ì†Œë¦¬ì¸ê°€'ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤.

    debug_print(f"MFCC ì¶”ì¶œ ì™„ë£Œ - shape: {mfcc.shape}, ê¸¸ì´: {duration:.3f}ì´ˆ")
    return mfcc, frame_times

def extract_mfcc_segment(mfcc: np.ndarray, frame_times: np.ndarray, start_time: float, end_time: float) -> np.ndarray:
    """
    ì‹œì‘, ë ì‹œê°„ì„ ì…ë ¥ ë°›ì•„ mfcc í–‰ë ¬ì„ ì¶”ì¶œ
    """
    debug_print(f"segment ì¶”ì¶œ - ì‹œê°„: {start_time:.3f}~{end_time:.3f}ì´ˆ")
    
    # frame_times: ê° í”„ë ˆì„ì´ ì˜¤ë””ì˜¤ì˜ ëª‡ ì´ˆ ì‹œì ì— í•´ë‹¹í•˜ëŠ”ì§€ ë‹´ì€ ë°°ì—´
    # np.serachsorted: start_time ë˜ëŠ” end_timeì— í•´ë‹¹í•˜ëŠ” í”„ë ˆì„ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ì¤Œ
    start_idx = np.searchsorted(frame_times, start_time, side = "left")
    end_idx = np.searchsorted(frame_times, end_time, side = "right")
    
    # ì¸ë±ìŠ¤ ë²”ìœ„ í™•ì¸
    start_idx = max(0, start_idx)
    end_idx = min(len(mfcc), end_idx)
    
    # ìµœì†Œ í”„ë ˆì„ ìˆ˜ í™•ì¸ (ë„ˆë¬´ ì§§ìœ¼ë©´ ì˜ë¯¸ ì—†ëŠ” ì„¸ê·¸ë¨¼íŠ¸)
    MIN_FRAMES = 5
    if end_idx - start_idx < MIN_FRAMES:
        debug_print(f"í”„ë ˆì„ ìˆ˜ ë¶€ì¡± - {end_idx - start_idx} < ìµœì†Œ ê¸°ì¤€: {MIN_FRAMES}")
        return np.array([])  # ë¹ˆ ë°°ì—´ ë°˜í™˜í•˜ì—¬ ëˆ„ë½ìœ¼ë¡œ ì²˜ë¦¬
    
    debug_print(f"ì¸ë±ìŠ¤: {start_idx}~{end_idx}, ê²°ê³¼ shape: {mfcc[start_idx:end_idx].shape}")
    # MFCC í–‰ë ¬ ì¤‘ì—ì„œ [start_time, end_time]ì— í•´ë‹¹í•˜ëŠ” êµ¬ê°„ë§Œ ì¶”ì¶œ
    return mfcc[start_idx:end_idx]

def compare_mfcc_segments(cached_segments: list[dict], user_mfcc: np.ndarray, user_frame_times: np.ndarray, job_id: str = None) -> list[dict]:
    """
    ê¸°ì¤€ ìŒì„±ì˜ mfcc í–‰ë ¬ê³¼ ìœ ì € ìŒì„±ì˜ mfcc í–‰ë ¬ì„ ì„œë¡œ ë¹„êµí•˜ì—¬ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê³„ì‚°
    ê°œì„ ëœ ë²„ì „: í‘œì¤€í¸ì°¨ ê¸°ë°˜ ë‹¨ì–´ ëˆ„ë½ ê°ì§€ ë¡œì§ í¬í•¨
    """
    debug_print(f"compare_mfcc_segments ì‹œì‘ - ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(cached_segments)}")
    debug_print(f"user_mfcc shape: {user_mfcc.shape}")
    
    # ìœ ì € ìŒì„± ì „ì²´ ê¸¸ì´ ê³„ì‚°
    user_duration = user_frame_times[-1] if len(user_frame_times) > 0 else 0
    
    results = []

    # ê¸°ì¤€ ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ë“¤ì˜ ì‹œì‘ ì§€ì ì„ 0ìœ¼ë¡œ ë§ì¶”ëŠ” ì •ê·œí™”ë¥¼ ìœ„í•œ offset
    # ëª¨ë“  segmentë“¤ì˜ ì‹œê°„ì— offsetë§Œí¼ ë¹¼ì„œ 0 ê¸°ì¤€ìœ¼ë¡œ ë§ì¶˜ë‹¤.
    offset = cached_segments[0]['start_time'] if cached_segments else 0

    # ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ ë°˜ë³µ     
    for i, segment in enumerate(cached_segments):
        word = segment["word"]
        start = segment["start_time"] - offset
        end = segment["end_time"] - offset
        
        debug_print(f"=== {i+1}ë²ˆì§¸ ë‹¨ì–´: '{word}' ({start:.3f}~{end:.3f}ì´ˆ) ===")
        
        # ğŸ” ê¸°ì¤€ MFCC ìƒì„¸ ì •ë³´ ì¶œë ¥
        ref_mfcc_data = segment.get("mfcc")
        debug_print(f"'{word}': ê¸°ì¤€ MFCC ì›ë³¸ íƒ€ì…: {type(ref_mfcc_data)}")
        
        if ref_mfcc_data is None:
            debug_print(f"'{word}': âŒ ê¸°ì¤€ MFCCê°€ None â†’ similarity = 0.0")
            similarity = 0.0
        elif ref_mfcc_data == []:
            debug_print(f"'{word}': âŒ ê¸°ì¤€ MFCCê°€ ë¹ˆ ë°°ì—´ â†’ similarity = 0.0")
            similarity = 0.0
        else:
            try:
                ref_mfcc = np.array(ref_mfcc_data)
                debug_print(f"'{word}': âœ… ê¸°ì¤€ MFCC shape = {ref_mfcc.shape}")
                debug_print(f"'{word}': ê¸°ì¤€ MFCC ìƒ˜í”Œ ê°’: {ref_mfcc.flatten()[:5] if ref_mfcc.size > 0 else 'empty'}")
                
                user_segment = extract_mfcc_segment(user_mfcc, user_frame_times, start, end)
                debug_print(f"'{word}': âœ… ìœ ì € segment shape = {user_segment.shape}")
                debug_print(f"'{word}': ìœ ì € segment ìƒ˜í”Œ ê°’: {user_segment.flatten()[:5] if user_segment.size > 0 else 'empty'}")

                if ref_mfcc.shape[0] == 0:
                    debug_print(f"'{word}': âŒ ê¸°ì¤€ MFCCê°€ ë¹ˆ ë°°ì—´ (shape[0]=0) â†’ similarity = 0.0")
                    similarity = 0.0
                elif user_segment.shape[0] == 0:
                    debug_print(f"'{word}': âŒ ìœ ì € segmentê°€ ë¹ˆ ë°°ì—´ (shape[0]=0) â†’ similarity = 0.0")
                    similarity = 0.0
                else:
                    # ğŸš€ ê°œì„ ëœ ë°©ì‹: í‘œì¤€í¸ì°¨ ê¸°ë°˜ ë‹¨ì–´ ëˆ„ë½ ê°ì§€ + ìœ í´ë¦¬ë””ì–¸ ê±°ë¦¬
                    similarity = frame_wise_euclidean_similarity(ref_mfcc, user_segment)
                    
                    if job_id:
                        # í‘œì¤€í¸ì°¨ ê³„ì‚°
                        ref_std = _calculate_std_deviation(ref_mfcc)
                        user_std = _calculate_std_deviation(user_segment)
                        std_ratio = user_std / ref_std if ref_std > 0 else 0.0
                        
                        # ì •ê·œí™” ì „ ì›ë³¸ í†µê³„
                        ref_raw_mean = np.mean(ref_mfcc, axis=0)
                        user_raw_mean = np.mean(user_segment, axis=0)

                        # ë””ë²„ê·¸ ì¶œë ¥ì„ ìœ„í•œ ì •ê·œí™”ëœ í‰ê· ê°’ ê³„ì‚°
                        ref_norm = _apply_cmvn(ref_mfcc)
                        user_norm = _apply_cmvn(user_segment)

                        # í”„ë ˆì„ë³„ ê±°ë¦¬ í†µê³„
                        min_frames = min(len(ref_norm), len(user_norm))
                        frame_distances = []
                        if min_frames > 0:
                            ref_aligned = ref_norm[:min_frames]
                            user_aligned = user_norm[:min_frames]
                            frame_distances = np.linalg.norm(ref_aligned - user_aligned, axis=1)
                        
                        print(f"[{job_id}] ğŸµ MFCC ë¹„êµ: '{word}'")
                        print(f"[{job_id}]   ê¸°ì¤€ ì›ë³¸ í‰ê· : {np.round(ref_raw_mean[:5], 2)}...")  # ì²˜ìŒ 5ê°œë§Œ
                        print(f"[{job_id}]   ìœ ì € ì›ë³¸ í‰ê· : {np.round(user_raw_mean[:5], 2)}...")
                        print(f"[{job_id}]   í‘œì¤€í¸ì°¨ ë¹„ìœ¨: {std_ratio:.2f} (ê¸°ì¤€: {ref_std:.2f}, ìœ ì €: {user_std:.2f})")
                        if len(frame_distances) > 0:
                            print(f"[{job_id}]   ê±°ë¦¬ min/mean/max: {frame_distances.min():.2f}/{frame_distances.mean():.2f}/{frame_distances.max():.2f}")
                        print(f"[{job_id}]   ìœ ì‚¬ë„: {similarity:.3f}")
                    
                    # ìœ ì‚¬ë„ ê°’ ê²€ì¦
                    if np.isnan(similarity):
                        debug_print(f"'{word}': âš ï¸ similarityê°€ NaN! â†’ 0.0ìœ¼ë¡œ ì„¤ì •")
                        similarity = 0.0
                        
            except Exception as e:
                debug_print(f"'{word}': âŒ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)} â†’ similarity = 0.0")
                similarity = 0.0
        
        # ì—°ì† ì„ í˜• ë³´ê°„ì„ ì‚¬ìš©í•œ ì ìˆ˜ í™˜ì‚° (0~100 ë²”ìœ„)
        # 
        # [ê¸°ì¡´ if-elif êµ¬ì¡°ì˜ ì„¤ì • ê·¼ê±°]
        # ë°ì´í„°ì…‹ ê²°ê³¼ ê¸°ë°˜ ì ìˆ˜ í™˜ì‚°:
        # - ì •ë‹µ ìŒì„± â‰ƒ0.45 â†’ 90-100ì  êµ¬ê°„
        # - íŒ€ì›(ì •ìƒ ë°œìŒ) â‰ƒ0.10 â†’ 70ì  
        # - ë‹¨ì–´ 2ê°œ ëˆ„ë½ â‰ƒ0.08 â†’ 50ì 
        # - ì•¡ì„¼íŠ¸ ì—†ì´ ë°œìŒ â‰ƒ0.09 â†’ 60ì   
        # - ì¹¨ë¬µ â‰ƒ0.02 â†’ 0ì 
        #
        # [ê¸°ì¡´ êµ¬ê°„ë³„ ë§¤í•‘ ë¡œì§]
        # if similarity >= 0.4:    # 0.4~0.53 => 90~100ì  (ì •ë‹µ ìˆ˜ì¤€)
        # elif similarity >= 0.3:  # 0.3~0.39 => 80~89ì  (ìš°ìˆ˜)
        # elif similarity >= 0.1:  # 0.1~0.29 => 70~79ì  (ì •ìƒ)
        # elif similarity >= 0.09: # 0.09~0.099 => 60~69ì  (ì•¡ì„¼íŠ¸ ì—†ìŒ)
        # elif similarity >= 0.08: # 0.08~0.089 => 50~59ì  (ë‹¨ì–´ ëˆ„ë½)
        # elif similarity >= 0.05: # 0.05~0.079 => 40~49ì  (ë¶€ì¡±)
        # else: 0.02 ì´í•˜ => 0ì  (ì¹¨ë¬µ), 0.02~0.049 => 0~39ì  (ë§¤ìš° ë¶€ì¡±)
        #
        # ìœ„ ë¡œì§ì„ ì—°ì† ì„ í˜• ë³´ê°„ìœ¼ë¡œ ë‹¨ìˆœí™”:
        adjusted_score = continuous_score(similarity)
        
        # ì •ê·œí™”ëœ ì ìˆ˜ (0~1 ë²”ìœ„)
        normalized_score = adjusted_score / 100.0
        
        if job_id:
            print(f"[{job_id}]   í™˜ì‚° ì ìˆ˜: {adjusted_score:.1f}/100 (ì›ì‹œ ìœ ì‚¬ë„: {similarity:.3f})")
        
        results.append({
            "word": word,
            "similarity": similarity,
            "adjusted_score": normalized_score  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”ëœ ì ìˆ˜ ì¶”ê°€
        })
        
        debug_print(f"'{word}': ìµœì¢… similarity = {similarity:.6f}, í™˜ì‚° ì ìˆ˜ = {adjusted_score:.1f}/100")

    debug_print(f"compare_mfcc_segments ì™„ë£Œ - ê²°ê³¼ ìˆ˜: {len(results)}")
    return results

def _calculate_std_deviation(mfcc):
    """
    MFCC íŠ¹ì„±ì˜ í‘œì¤€í¸ì°¨ ê³„ì‚°
    
    Parameters:
    -----------
    mfcc : ndarray
        MFCC íŠ¹ì„± (ì‹œê°„, íŠ¹ì„±)
        
    Returns:
    --------
    float
        MFCC ê³„ìˆ˜ì˜ í‰ê·  í‘œì¤€í¸ì°¨
    """
    if mfcc.shape[0] == 0:
        return 0.0
        
    # ê° MFCC ê³„ìˆ˜ì˜ í‘œì¤€í¸ì°¨ ê³„ì‚°
    if mfcc.shape[1] >= 13:  # ê¸°ë³¸ MFCC (ë¸íƒ€ íŠ¹ì„± í¬í•¨ ê°€ëŠ¥)
        # ì²« 13ê°œ ê³„ìˆ˜ë§Œ ì‚¬ìš© (ë¸íƒ€ íŠ¹ì„± ì œì™¸)
        std_dev = np.mean(np.std(mfcc[:, :13], axis=0))
    else:
        std_dev = np.mean(np.std(mfcc, axis=0))
    
    return std_dev