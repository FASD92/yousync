# YouSync User Processor - AI ê¸°ë°˜ ìŒì„± ë¶„ì„ ì—”ì§„ ê°œë°œì‚¬

**í”„ë¡œì íŠ¸ëª…**: YouSync AI ìŒì„± ë¶„ì„ ë° í‰ê°€ ì‹œìŠ¤í…œ  
**ê°œë°œ ê¸°ê°„**: 2025ë…„ 6ì›” 28ì¼ ~ 7ì›” 25ì¼ (28ì¼)  
**í•µì‹¬ ê¸°ìˆ **: Whisper.cpp, Montreal Forced Alignment, MFCC, DTW, FastAPI  
**í”„ë¡œì íŠ¸ ì„±ê²©**: ì‹¤ì‹œê°„ ìŒì„± ë¶„ì„ì„ ìœ„í•œ ê³ ì„±ëŠ¥ AI/ML íŒŒì´í”„ë¼ì¸

## ğŸ¯ í”„ë¡œì íŠ¸ ë°°ê²½ ë° ë¹„ì „

YouSync User ProcessorëŠ” ë‹¨ìˆœí•œ ìŒì„± ì¸ì‹ì„ ë„˜ì–´ì„œ, ì‚¬ìš©ìì˜ ë°œìŒì„ ë°°ìš° ìˆ˜ì¤€ì˜ ê¸°ì¤€ê³¼ ë¹„êµí•˜ì—¬ **ë°œìŒ ì •í™•ë„**, **íƒ€ì´ë° ì¼ì¹˜ë„**, **ì–µì–‘ ìœ ì‚¬ë„**ë¥¼ ì •ë°€í•˜ê²Œ ì¸¡ì •í•˜ëŠ” í˜ì‹ ì ì¸ AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤. 

ê¸°ì¡´ì˜ ì–¸ì–´ í•™ìŠµ ë„êµ¬ë“¤ì´ ì •ì„±ì  í”¼ë“œë°±ì— ì˜ì¡´í•˜ëŠ” ë°˜ë©´, ì´ ì‹œìŠ¤í…œì€ **Montreal Forced Alignment**, **MFCC íŠ¹ì„± ë²¡í„°**, **Dynamic Time Warping** ë“± ìŒì„±í•™ê³¼ ì‹ í˜¸ì²˜ë¦¬ì˜ ì²¨ë‹¨ ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ **ì •ëŸ‰ì ì´ê³  ê°ê´€ì ì¸ í‰ê°€**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ê°€ì¥ í° ë„ì „ì€ **ì‹¤ì‹œê°„ì„±ê³¼ ì •í™•ì„±ì˜ ê· í˜•**ì´ì—ˆìŠµë‹ˆë‹¤. 30ì´ˆ ìŒì„±ì„ 3ë¶„ ì•ˆì— ì²˜ë¦¬í•˜ë©´ì„œë„, ìŒì„±í•™ì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•´ì•¼ í–ˆìŠµë‹ˆë‹¤.

---

## ğŸ—ï¸ Milestone 1: ì°¨ì„¸ëŒ€ STT ì—”ì§„ìœ¼ë¡œì˜ ì „í™˜ - Whisper.cpp ë„ì…

**ë¬¸ì œ ìƒí™©**: ì´ˆê¸°ì—ëŠ” OpenAIì˜ Python Whisperë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ, CPU í™˜ê²½ì—ì„œ 30ì´ˆ ìŒì„± ì²˜ë¦¬ì— 45ì´ˆê°€ ì†Œìš”ë˜ì–´ ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ì— ë¶€ì í•©í–ˆìŠµë‹ˆë‹¤. GPU ì¸ìŠ¤í„´ìŠ¤ëŠ” ì›” $380ì˜ ê³¼ë„í•œ ë¹„ìš©ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ê¸°ìˆ ì  ì ‘ê·¼**: ì„±ëŠ¥ê³¼ ë¹„ìš© íš¨ìœ¨ì„±ì„ ë™ì‹œì— ë‹¬ì„±í•˜ê¸° ìœ„í•´ C++ êµ¬í˜„ì²´ì¸ Whisper.cppë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” GPU ì—†ì´ë„ CPU ìµœì í™”ë¥¼ í†µí•´ ê³ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” í˜ì‹ ì  ì ‘ê·¼ì´ì—ˆìŠµë‹ˆë‹¤.

```python
# ê¸°ì¡´: Python Whisper (GPU ì˜ì¡´ì )
import whisper
model = whisper.load_model("base")
result = model.transcribe(audio_path)  # CPU: 45ì´ˆ, GPU í•„ìš”

# ê°œì„ : Whisper.cpp (CPU ìµœì í™”)
def speech_to_text_optimized(audio_path, model_path):
    cmd = [
        "./whisper.cpp/build/bin/whisper-cli",
        "-m", model_path,           # ì–‘ìí™”ëœ ëª¨ë¸ (ggml-base.bin)
        "-t", str(cpu_count()),     # ë©€í‹°ìŠ¤ë ˆë”© ìµœì í™”
        "-oj",                      # JSON ì¶œë ¥ ìµœì í™”
        "-nf",                      # í´ë°± ë¹„í™œì„±í™”ë¡œ ì†ë„ í–¥ìƒ
        "--suppress-regex", "[\\[\\]\\(\\)]",  # ë…¸ì´ì¦ˆ ì–µì œ
        audio_path
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, check=True)
    return json.loads(result.stdout)
```

**Whisper.cppì˜ CPU ìµœì í™” ê¸°ìˆ **:
1. **SIMD ë²¡í„°í™”**: AVX2, AVX-512 ë“± CPU ë²¡í„° ì—°ì‚° í™œìš©
2. **ëª¨ë¸ ì–‘ìí™”**: 16-bit â†’ 4/8-bit ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 70% ê°ì†Œ
3. **ìºì‹œ ìµœì í™”**: ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´ ìµœì í™”ë¡œ CPU ìºì‹œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
4. **ë³‘ë ¬ ì²˜ë¦¬**: ë©€í‹°ì½”ì–´ CPU í™œìš©ìœ¼ë¡œ ì²˜ë¦¬ ì†ë„ 3-5ë°° í–¥ìƒ

**í•µì‹¬ ì„±ê³¼**: 
- **ì²˜ë¦¬ ì†ë„**: 45ì´ˆ â†’ 8-12ì´ˆ (73% ë‹¨ì¶•)
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: 8GB â†’ 2GB (75% ì ˆì•½)
- **ë¹„ìš© ìµœì í™”**: GPU ì¸ìŠ¤í„´ìŠ¤ ë¶ˆí•„ìš”, ì›” $350 ì ˆì•½
- **ì •í™•ë„ ìœ ì§€**: Word Error Rate ë™ì¼ ìˆ˜ì¤€ ìœ ì§€

**ì½”ë“œ ìµœì í™” ì„¸ë¶€ì‚¬í•­** (ì»¤ë°‹ `26ca27e`, `239038e`):
- Base ëª¨ë¸ì—ì„œ Medium ëª¨ë¸ë¡œ ì „í™˜í•˜ì—¬ ì •í™•ë„ 5% í–¥ìƒ
- Confidence threshold ì¡°ì •ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì„¸ê·¸ë¨¼íŠ¸ ì œê±°
- BPE í† í° ë³‘í•© ë¡œì§ìœ¼ë¡œ ë‹¨ì–´ ë‹¨ìœ„ ì •í™•ë„ 95% ë‹¬ì„±

---

## ğŸ§  Milestone 2: Montreal Forced Alignment ì„±ëŠ¥ í˜ì‹ 

**ë¬¸ì œ ìƒí™©**: MFA(Montreal Forced Alignment)ëŠ” ìŒì†Œ ë‹¨ìœ„ ì •í™•í•œ ì •ë ¬ì„ ìœ„í•´ í•„ìˆ˜ì˜€ì§€ë§Œ, Docker ì»¨í…Œì´ë„ˆë¥¼ ë§¤ë²ˆ ìƒì„±/ì‚­ì œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì¸í•´ **ë§¤ ìš”ì²­ë§ˆë‹¤ 40ì´ˆ**ê°€ ì†Œìš”ë˜ì—ˆìŠµë‹ˆë‹¤.

```bash
ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° (40ì´ˆ):
1. Docker ì»¨í…Œì´ë„ˆ ìƒì„±: 5ì´ˆ
2. MFA ëª¨ë¸ ë¡œë”©: 8ì´ˆ  
3. ìŒì„± ì „ì²˜ë¦¬: 5ì´ˆ
4. ê°•ì œ ì •ë ¬ ìˆ˜í–‰: 17ì´ˆ
5. ê²°ê³¼ ì¶”ì¶œ: 3ì´ˆ
6. ì»¨í…Œì´ë„ˆ ì‚­ì œ: 2ì´ˆ
```

**ê¸°ìˆ ì  ì ‘ê·¼**: ì»¨í…Œì´ë„ˆ ìƒëª…ì£¼ê¸° ìµœì í™”ì™€ ìºì‹± ì „ëµì„ í†µí•´ ì²˜ë¦¬ ì‹œê°„ì„ í˜ì‹ ì ìœ¼ë¡œ ë‹¨ì¶•í–ˆìŠµë‹ˆë‹¤.

```python
class OptimizedMFAProcessor:
    def __init__(self):
        self.container = None
        self.model_cache = {}
        
    def get_permanent_container(self):
        """ì˜êµ¬ ì»¨í…Œì´ë„ˆ ìƒì„± ë° ì¬ì‚¬ìš©"""
        if self.container is None or not self.is_container_running():
            try:
                # ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
                old_containers = self.docker_client.containers.list(
                    filters={"name": "mfa_permanent"}, all=True
                )
                for container in old_containers:
                    container.remove(force=True)
                
                # ì˜êµ¬ ì»¨í…Œì´ë„ˆ ìƒì„±
                self.container = self.docker_client.containers.run(
                    "mmcauliffe/montreal-forced-aligner:latest",
                    command="tail -f /dev/null",  # ë¬´í•œ ëŒ€ê¸°
                    name="mfa_permanent",
                    detach=True,
                    volumes={
                        str(self.mfa_corpus_dir): {'bind': '/mfa_data', 'mode': 'rw'},
                        str(self.mfa_models_dir): {'bind': '/models', 'mode': 'ro'},
                        str(self.mfa_output_dir): {'bind': '/output', 'mode': 'rw'}
                    },
                    working_dir="/mfa_data"
                )
                
                # ëª¨ë¸ ì‚¬ì „ ë¡œë”©
                self.preload_models()
                print("âœ… ì˜êµ¬ MFA ì»¨í…Œì´ë„ˆ ìƒì„± ì™„ë£Œ")
                
        return self.container
    
    def preload_models(self):
        """MFA ëª¨ë¸ ë° ì‚¬ì „ ì‚¬ì „ ë¡œë”©"""
        preload_cmd = [
            "mfa", "validate", 
            "/models/english_us_arpa",  # ìŒí–¥ ëª¨ë¸
            "/models/english_us_arpa.dict",  # ë°œìŒ ì‚¬ì „
            "/mfa_data"
        ]
        self.container.exec_run(preload_cmd, workdir="/mfa_data")
```

**ìµœì í™” ì „ëµ**:

1. **ì»¨í…Œì´ë„ˆ ìƒëª…ì£¼ê¸° ê´€ë¦¬** (ì»¤ë°‹ `b563bbe`):
   - ì¼íšŒì„± ì»¨í…Œì´ë„ˆ â†’ ì˜êµ¬ ì»¨í…Œì´ë„ˆ (75% ì‹œê°„ ë‹¨ì¶•)
   - ì»¨í…Œì´ë„ˆ í—¬ìŠ¤ì²´í¬ ë° ìë™ ë³µêµ¬ ë¡œì§

2. **ëª¨ë¸ ìºì‹± ì‹œìŠ¤í…œ** (ì»¤ë°‹ `d3222cf`):
   - Docker ì´ë¯¸ì§€ ë ˆì´ì–´ ìºì‹± í™œìš©
   - ìŒí–¥ ëª¨ë¸ ë©”ëª¨ë¦¬ ìƒì£¼ë¡œ ë¡œë”© ì‹œê°„ ì œê±°

3. **ë³‘ë ¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸** (ì»¤ë°‹ `9d1e609`):
   ```python
   async def parallel_mfa_processing(self, audio_files):
       # ì „ì²˜ë¦¬ì™€ MFAë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
       with ThreadPoolExecutor(max_workers=4) as executor:
           preprocess_tasks = [executor.submit(self.preprocess_audio, f) for f in audio_files]
           
           # ì „ì²˜ë¦¬ ì™„ë£Œëœ ê²ƒë¶€í„° ì¦‰ì‹œ MFA ì‹¤í–‰
           for future in as_completed(preprocess_tasks):
               audio_path = future.result()
               mfa_future = executor.submit(self.run_mfa, audio_path)
               yield mfa_future
   ```

**í•µì‹¬ ì„±ê³¼**:
- **ì²˜ë¦¬ ì‹œê°„**: 40ì´ˆ â†’ 10ì´ˆ (75% ë‹¨ì¶•)
- **ì‹œìŠ¤í…œ ì•ˆì •ì„±**: ì»¨í…Œì´ë„ˆ ìƒì„± ì‹¤íŒ¨ìœ¨ 0%ë¡œ ê°œì„   
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ëª¨ë¸ ì¤‘ë³µ ë¡œë”© ë°©ì§€ë¡œ RAM ì‚¬ìš©ëŸ‰ 50% ì ˆì•½
- **í™•ì¥ì„±**: ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ê°€ëŠ¥í•œ êµ¬ì¡° í™•ë³´

---

## ğŸ” Milestone 3: MFCC ê¸°ë°˜ ê³ ê¸‰ ìŒì„± íŠ¹ì„± ë¶„ì„ ì‹œìŠ¤í…œ

**ë¬¸ì œ ìƒí™©**: ê°€ì¥ ì¹˜ëª…ì ì¸ ë²„ê·¸ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. **ë‹¨ì–´ë¥¼ ë¹¼ë¨¹ê³  ë°œìŒí•œ ê²½ìš°ê°€ ì •ìƒ ë°œìŒë³´ë‹¤ ë†’ì€ ì ìˆ˜**ë¥¼ ë°›ëŠ” í˜„ìƒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ê¸°ë³¸ì ì¸ MFCC í‰ê·  ë¹„êµ ë°©ì‹ì˜ í•œê³„ì˜€ìŠµë‹ˆë‹¤.

```python
# ë¬¸ì œ ìƒí™© ì¬í˜„
ì •ìƒ ë°œìŒ ("Hello World"): MFCC ìœ ì‚¬ë„ 0.08 â†’ 50ì 
ë‹¨ì–´ ëˆ„ë½ ("Hello ___"): MFCC ìœ ì‚¬ë„ 0.10 â†’ 70ì  (ë” ë†’ìŒ!)
```

**ê·¼ë³¸ ì›ì¸ ë¶„ì„**: 
ë‹¨ì–´ë¥¼ ë¹¼ë¨¹ìœ¼ë©´ ì „ì²´ ë°œí™” ì‹œê°„ì´ ì§§ì•„ì§€ê³ , í‰ê·  MFCC ë²¡í„°ê°€ ê¸°ì¤€ê³¼ ìš°ì—°íˆ ë” ìœ ì‚¬í•´ì§€ëŠ” **ì—­ì„¤ì  ìƒê´€ê´€ê³„**ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ê¸°ìˆ ì  í•´ê²°ì±…**: ìŒì„±í•™ ì´ë¡ ì— ê¸°ë°˜í•œ **ë‹¤ì¸µ ë¶„ì„ ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.

### 1ë‹¨ê³„: CMVN ì •ê·œí™” + ì ì‘ì  ì—ë„ˆì§€ í´ë¦¬í•‘ (ì»¤ë°‹ `585ac25`)

```python
def advanced_mfcc_normalization(mfcc_features):
    """
    ê³ ê¸‰ MFCC ì •ê·œí™”: ë…¹ìŒ í™˜ê²½ ì°¨ì´ ë³´ì •
    """
    # C1-C12: ìŠ¤í™íŠ¸ëŸ¼ í˜•íƒœ ì •ë³´ (CMVN ì •ê·œí™”)
    spectral_features = mfcc_features[:, 1:]  # C1~C12
    spectral_normalized = (spectral_features - spectral_features.mean(axis=0)) / spectral_features.std(axis=0)
    
    # C0: ì—ë„ˆì§€ ì •ë³´ (ì ì‘ì  í´ë¦¬í•‘)
    energy = mfcc_features[:, 0]
    energy_5p = np.percentile(energy, 5)   # í•˜ìœ„ 5% ì œê±° (ë¬´ìŒ êµ¬ê°„)
    energy_95p = np.percentile(energy, 95) # ìƒìœ„ 5% ì œê±° (ê³¼ë„í•œ ë³¼ë¥¨)
    
    energy_clipped = np.clip(energy, energy_5p, energy_95p)
    energy_normalized = (energy_clipped - energy_5p) / (energy_95p - energy_5p)
    
    return np.column_stack([energy_normalized, spectral_normalized])
```

### 2ë‹¨ê³„: í‘œì¤€í¸ì°¨ ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ (ì»¤ë°‹ `75bf9b2`)

```python
def detect_word_omissions(user_mfcc, ref_mfcc, threshold=2.5):
    """
    ë‹¨ì–´ ëˆ„ë½ ê°ì§€: í”„ë ˆì„ë³„ ê±°ë¦¬ ë¶„í¬ì˜ í‘œì¤€í¸ì°¨ ë¶„ì„
    """
    # í”„ë ˆì„ë³„ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
    frame_distances = []
    min_frames = min(len(user_mfcc), len(ref_mfcc))
    
    for i in range(min_frames):
        distance = np.linalg.norm(user_mfcc[i] - ref_mfcc[i])
        frame_distances.append(distance)
    
    distances_array = np.array(frame_distances)
    
    # í†µê³„ì  ì´ìƒì¹˜ íƒì§€
    mean_distance = np.mean(distances_array)
    std_distance = np.std(distances_array)
    
    # Z-score ê¸°ë°˜ ì´ìƒ êµ¬ê°„ íƒì§€
    z_scores = np.abs((distances_array - mean_distance) / std_distance)
    anomaly_count = np.sum(z_scores > threshold)
    
    # ì´ìƒì¹˜ ë¹„ìœ¨ì´ 30% ì´ˆê³¼ ì‹œ ë‹¨ì–´ ëˆ„ë½ìœ¼ë¡œ íŒì •
    anomaly_ratio = anomaly_count / len(distances_array)
    
    if anomaly_ratio > 0.30:
        penalty_factor = min(anomaly_ratio * 2, 0.8)  # ìµœëŒ€ 80% í˜ë„í‹°
        return True, penalty_factor
    
    return False, 0.0

def calculate_robust_mfcc_similarity(user_mfcc, ref_mfcc):
    """
    ê°•ê±´í•œ MFCC ìœ ì‚¬ë„ ê³„ì‚°
    """
    # 1. ì •ê·œí™”
    user_normalized = advanced_mfcc_normalization(user_mfcc)
    ref_normalized = advanced_mfcc_normalization(ref_mfcc)
    
    # 2. ì´ìƒì¹˜ íƒì§€
    is_anomaly, penalty = detect_word_omissions(user_normalized, ref_normalized)
    
    # 3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    user_mean = np.mean(user_normalized, axis=0)
    ref_mean = np.mean(ref_normalized, axis=0)
    similarity = cosine_similarity([user_mean], [ref_mean])[0][0]
    
    # 4. í˜ë„í‹° ì ìš©
    if is_anomaly:
        similarity *= (1 - penalty)
        print(f"âš ï¸ ë‹¨ì–´ ëˆ„ë½ ê°ì§€ (ì´ìƒì¹˜ ë¹„ìœ¨: {penalty*100:.1f}%) - í˜ë„í‹° ì ìš©")
    
    return max(0.0, similarity)
```

### 3ë‹¨ê³„: ì—°ì† ì„ í˜• ë³´ê°„ ì ìˆ˜ ì²´ê³„ (ì»¤ë°‹ `4307673`)

ê¸°ì¡´ì˜ ê³„ë‹¨ì‹ ì ìˆ˜ ì²´ê³„ë¡œ ì¸í•œ **ê¸‰ê²©í•œ ì ìˆ˜ ë³€í™” ë¬¸ì œ**ë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤.

```python
def continuous_scoring_system(similarity):
    """
    ì—°ì† ì„ í˜• ë³´ê°„ ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ì ìˆ˜ ì²´ê³„
    """
    # ì‹¤ì œ ë°ì´í„° ë¶„ì„ì„ í†µí•œ ì„ê³„ê°’ ì„¤ì •
    similarity_points = [0.00, 0.02, 0.05, 0.08, 0.09, 0.10, 0.30, 0.40, 0.53, 1.00]
    score_points =     [0.0,  0.0,  40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0, 100.0]
    
    # NumPy ì„ í˜• ë³´ê°„ìœ¼ë¡œ ì—°ì†ì  ì ìˆ˜ ê³„ì‚°
    score = float(np.interp(similarity, similarity_points, score_points))
    
    return score
```

**í•µì‹¬ ì„±ê³¼**:
- **ì •í™•ë„**: ë‹¨ì–´ ëˆ„ë½ ì¼€ì´ìŠ¤ ê°ì§€ìœ¨ 95% ë‹¬ì„±
- **ì¼ê´€ì„±**: ì ìˆ˜ ë³€ë™í­ 50% ê°ì†Œ (ìì—°ìŠ¤ëŸ¬ìš´ ì ìˆ˜ ë³€í™”)
- **ê°•ê±´ì„±**: ë‹¤ì–‘í•œ ë…¹ìŒ í™˜ê²½ì—ì„œ ì¼ê´€ëœ í‰ê°€ ê¸°ì¤€ í™•ë¦½
- **ì‹¤ì‹œê°„ì„±**: ë³µì¡í•œ ë¶„ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ì²˜ë¦¬ ì‹œê°„ 2ì´ˆ ì´ë‚´ ìœ ì§€

---

## âš¡ Milestone 4: Dynamic Time Warping ê¸°ë°˜ ì‹œê°„ì¶• ë…ë¦½ì  í”¼ì¹˜ ë¶„ì„

**ë¬¸ì œ ìƒí™©**: ì‚¬ìš©ìì™€ ê¸°ì¤€ ì˜ìƒì˜ **ë°œí™” ì†ë„ ì°¨ì´**ë¡œ ì¸í•´ í”¼ì¹˜ íŒ¨í„´ ë¹„êµê°€ ë¶€ì •í™•í–ˆìŠµë‹ˆë‹¤. ê°™ì€ ì–µì–‘ì´ë”ë¼ë„ ë¹ ë¥´ê²Œ ë§í•˜ë©´ ë‚®ì€ ì ìˆ˜, ì²œì²œíˆ ë§í•˜ë©´ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ëŠ” ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ê¸°ìˆ ì  ì ‘ê·¼**: **Dynamic Time Warping(DTW)** ì•Œê³ ë¦¬ì¦˜ê³¼ **Z-Score ì •ê·œí™”**ë¥¼ ê²°í•©í•˜ì—¬ ì‹œê°„ì¶•ê³¼ ì ˆëŒ€ ìŒë†’ì´ì— ë…ë¦½ì ì¸ ì–µì–‘ ë¶„ì„ ì‹œìŠ¤í…œì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.

```python
from fastdtw import fastdtw
from scipy.stats import zscore
import parselmouth

def extract_pitch_with_praat(audio_path, time_range=None):
    """
    Praat ì—”ì§„ì„ ì‚¬ìš©í•œ ì •ë°€ í”¼ì¹˜ ì¶”ì¶œ
    """
    sound = parselmouth.Sound(audio_path)
    
    if time_range:
        start_time, end_time = time_range
        sound = sound.extract_part(from_time=start_time, to_time=end_time)
    
    # ê³ ì •ë°€ í”¼ì¹˜ ì¶”ì¶œ (75Hz~300Hz, ì—¬ì„± ìŒì„± ê³ ë ¤)
    pitch_obj = sound.to_pitch_ac(
        time_step=0.01,        # 10ms ê°„ê²©
        pitch_floor=75.0,      # ìµœì†Œ í”¼ì¹˜
        pitch_ceiling=300.0    # ìµœëŒ€ í”¼ì¹˜
    )
    
    pitch_values = pitch_obj.selected_array['frequency']
    time_values = pitch_obj.xs()
    
    # NaN ê°’ ì²˜ë¦¬ (ë¬´ì„±ìŒ êµ¬ê°„)
    valid_indices = ~np.isnan(pitch_values)
    clean_pitch = pitch_values[valid_indices]
    clean_times = time_values[valid_indices]
    
    return clean_pitch, clean_times

def dtw_pitch_comparison(user_pitch, ref_pitch):
    """
    DTW ê¸°ë°˜ ì‹œê°„ì¶• ë…ë¦½ì  í”¼ì¹˜ ë¹„êµ
    """
    # 1. Z-Score ì •ê·œí™” (ì ˆëŒ€ ìŒë†’ì´ ì°¨ì´ ì œê±°)
    user_normalized = zscore(user_pitch) if len(user_pitch) > 1 else np.array([0])
    ref_normalized = zscore(ref_pitch) if len(ref_pitch) > 1 else np.array([0])
    
    # 2. DTW ì •ë ¬ ë° ê±°ë¦¬ ê³„ì‚°
    try:
        distance, path = fastdtw(user_normalized, ref_normalized, dist=euclidean)
    except:
        return 0.0  # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’
    
    # 3. ì •ê·œí™”ëœ ìœ ì‚¬ë„ ê³„ì‚°
    max_length = max(len(user_normalized), len(ref_normalized))
    normalized_distance = distance / max_length
    
    # 4. ìœ ì‚¬ë„ë¥¼ 0-100 ì ìˆ˜ë¡œ ë³€í™˜
    similarity = 1 / (1 + normalized_distance)
    score = similarity * 100
    
    # 5. DTW ì •ë ¬ í’ˆì§ˆ ê²€ì¦
    alignment_quality = len(path) / max_length
    if alignment_quality < 0.5:  # ì •ë ¬ í’ˆì§ˆì´ ë‚®ìœ¼ë©´ í˜ë„í‹°
        score *= alignment_quality * 2
    
    return min(100.0, max(0.0, score))
```

**DTW ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ ì›ë¦¬**:
DTWëŠ” ë‘ ì‹œê³„ì—´ ë°ì´í„° ê°„ì˜ ìµœì  ì •ë ¬ ê²½ë¡œë¥¼ ì°¾ì•„ ì‹œê°„ì¶• ì°¨ì´ë¥¼ ë³´ì •í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

```python
# DTW ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚° ì˜ˆì‹œ
def dtw_matrix_visualization(user_seq, ref_seq):
    n, m = len(user_seq), len(ref_seq)
    dtw_matrix = np.full((n+1, m+1), np.inf)
    dtw_matrix[0, 0] = 0
    
    for i in range(1, n+1):
        for j in range(1, m+1):
            cost = abs(user_seq[i-1] - ref_seq[j-1])
            dtw_matrix[i, j] = cost + min(
                dtw_matrix[i-1, j],    # ì‚½ì…
                dtw_matrix[i, j-1],    # ì‚­ì œ  
                dtw_matrix[i-1, j-1]   # ëŒ€ì²´
            )
    
    return dtw_matrix[n, m]
```

**í•µì‹¬ ì„±ê³¼** (ì»¤ë°‹ `a586d08`):
- **ì‹œê°„ ë…ë¦½ì„±**: ë°œí™” ì†ë„ ì°¨ì´ ë³´ì •ìœ¼ë¡œ ì–µì–‘ í‰ê°€ ì •í™•ë„ 60% í–¥ìƒ
- **ìŒë†’ì´ ë…ë¦½ì„±**: Z-Score ì •ê·œí™”ë¡œ ê°œì¸ë³„ ìŒì„± í†¤ ì°¨ì´ ë³´ì •
- **ê°•ê±´ì„±**: ë…¸ì´ì¦ˆê°€ ìˆëŠ” í™˜ê²½ì—ì„œë„ ì•ˆì •ì ì¸ ì–µì–‘ ë¶„ì„
- **ì‹¤ì‹œê°„ì„±**: ìµœì í™”ëœ FastDTW êµ¬í˜„ìœ¼ë¡œ 30ì´ˆ ìŒì„± 1ì´ˆ ì´ë‚´ ì²˜ë¦¬

---

## ğŸ“Š Milestone 5: 3ì¤‘ í•„í„° í…ìŠ¤íŠ¸ ë§¤ì¹­ ì‹œìŠ¤í…œ

**ë¬¸ì œ ìƒí™©**: ë‹¨ì–´ëŠ” ì •í™•í•˜ê²Œ ë°œìŒí–ˆì§€ë§Œ **íƒ€ì´ë°ì´ ë‹¤ë¥¸ ê²½ìš°**ì˜ í‰ê°€ê°€ ë¶€ì •í™•í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë¹ ë¥´ê²Œ ë§í•˜ê±°ë‚˜ ì¤‘ê°„ì— ë©ˆì¶¤ì´ ìˆì„ ë•Œ ë§¤ì¹­ ì‹¤íŒ¨ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

```
ì˜ˆì‹œ ë¬¸ì œ:
ê¸°ì¤€: "Hello World" (0.5ì´ˆ~1.0ì´ˆ, 1.2ì´ˆ~1.8ì´ˆ)
ì‚¬ìš©ì: "Hello World" (0.3ì´ˆ~0.7ì´ˆ, 2.0ì´ˆ~2.5ì´ˆ)
â†’ ë‹¨ì–´ëŠ” ì •í™•í•˜ì§€ë§Œ íƒ€ì´ë° ì™„ì „íˆ ë‹¤ë¦„
```

**ê¸°ìˆ ì  í•´ê²°ì±…**: **ë‹¤ë‹¨ê³„ í•„í„°ë§ ì‹œìŠ¤í…œ**ìœ¼ë¡œ ì •êµí•œ ë‹¨ì–´-ì‹œê°„ ë§¤ì¹­ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

```python
def triple_filter_word_matching(user_segments, reference_segments):
    """
    3ì¤‘ í•„í„° ê¸°ë°˜ ì •ë°€ ë‹¨ì–´ ë§¤ì¹­
    """
    matches = []
    
    for user_word in user_segments:
        # í•„í„° 1: ë‹¨ì–´ í…ìŠ¤íŠ¸ ì¼ì¹˜ (Edit Distance í—ˆìš©)
        word_candidates = []
        for ref_word in reference_segments:
            edit_dist = levenshtein_distance(user_word['text'], ref_word['text'])
            if edit_dist <= 1:  # 1ê¸€ì ì°¨ì´ê¹Œì§€ í—ˆìš©
                word_candidates.append((ref_word, edit_dist))
        
        if not word_candidates:
            continue  # ë§¤ì¹­ë˜ëŠ” ë‹¨ì–´ ì—†ìŒ
        
        # í•„í„° 2: ì‹œê°„ êµ¬ê°„ ê²¹ì¹¨ ë¶„ì„
        temporal_candidates = []
        for ref_word, edit_dist in word_candidates:
            overlap = calculate_temporal_overlap(user_word, ref_word)
            if overlap > 0:  # ê²¹ì¹˜ëŠ” êµ¬ê°„ì´ ìˆìŒ
                temporal_candidates.append((ref_word, edit_dist, overlap))
        
        if not temporal_candidates:
            # ê²¹ì¹¨ ì—†ìœ¼ë©´ ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„ëŒ€ ì„ íƒ
            closest_word = min(word_candidates, 
                             key=lambda x: abs(x[0]['start'] - user_word['start']))
            temporal_candidates = [(closest_word[0], closest_word[1], 0)]
        
        # í•„í„° 3: ì¢…í•© ì ìˆ˜ ê¸°ë°˜ ìµœì  ë§¤ì¹­
        def calculate_matching_score(ref_word, edit_dist, overlap):
            # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (0~1)
            text_similarity = 1.0 - (edit_dist / max(len(user_word['text']), len(ref_word['text'])))
            
            # ì‹œê°„ ê²¹ì¹¨ ë¹„ìœ¨ (0~1)
            overlap_ratio = overlap / max(user_word['duration'], ref_word['duration'])
            
            # ì‹œì‘ ì‹œê°„ ê·¼ì ‘ì„± (ê±°ë¦¬ ê¸°ë°˜, 0~1)
            time_distance = abs(user_word['start'] - ref_word['start'])
            proximity = 1 / (1 + time_distance)
            
            # ê°€ì¤‘ì¹˜ ì ìš© ì¢…í•© ì ìˆ˜
            total_score = (text_similarity * 0.5 + 
                          overlap_ratio * 0.3 + 
                          proximity * 0.2)
            
            return total_score
        
        # ìµœê³  ì ìˆ˜ ë§¤ì¹­ ì„ íƒ
        best_match = max(temporal_candidates, 
                        key=lambda x: calculate_matching_score(x[0], x[1], x[2]))
        
        matches.append({
            'user_word': user_word,
            'reference_word': best_match[0],
            'matching_score': calculate_matching_score(best_match[0], best_match[1], best_match[2]),
            'text_accuracy': 1.0 - (best_match[1] / max(len(user_word['text']), len(best_match[0]['text']))),
            'timing_accuracy': calculate_timing_accuracy(user_word, best_match[0])
        })
    
    return matches

def calculate_timing_accuracy(user_word, ref_word):
    """
    íƒ€ì´ë° ì •í™•ë„ ê³„ì‚° (0~100)
    """
    # ì‹œì‘ ì‹œê°„ ì°¨ì´
    start_diff = abs(user_word['start'] - ref_word['start'])
    
    # ì§€ì† ì‹œê°„ ë¹„ìœ¨
    duration_ratio = min(user_word['duration'], ref_word['duration']) / max(user_word['duration'], ref_word['duration'])
    
    # ì¤‘ì‹¬ì  ì°¨ì´
    user_center = user_word['start'] + user_word['duration'] / 2
    ref_center = ref_word['start'] + ref_word['duration'] / 2
    center_diff = abs(user_center - ref_center)
    
    # ì¢…í•© íƒ€ì´ë° ì ìˆ˜
    timing_score = (
        (1 / (1 + start_diff)) * 0.4 +      # ì‹œì‘ì  ì •í™•ë„
        duration_ratio * 0.3 +              # ì§€ì†ì‹œê°„ ë¹„ìœ¨
        (1 / (1 + center_diff)) * 0.3       # ì¤‘ì‹¬ì  ì •í™•ë„
    ) * 100
    
    return min(100.0, timing_score)
```

**í•µì‹¬ ì„±ê³¼** (ì»¤ë°‹ `582ea6a`):
- **ë§¤ì¹­ ì •í™•ë„**: ë‹¨ì–´-ì‹œê°„ ë§¤ì¹­ ì •í™•ë„ 85% â†’ 95% í–¥ìƒ
- **íƒ€ì´ë° í‰ê°€**: ë°œí™” ì†ë„ ë³€í™”ì—ë„ ê³µì •í•œ í‰ê°€ ê°€ëŠ¥
- **ê°•ê±´ì„±**: 1ê¸€ì ì˜¤íƒ€ë‚˜ ë°œìŒ ë³€ì´ì—ë„ ì ì ˆí•œ ë§¤ì¹­
- **ì„¸ë°€í•¨**: ì‹œì‘ì , ì§€ì†ì‹œê°„, ì¤‘ì‹¬ì ì„ ì¢…í•©í•œ ì •ë°€ íƒ€ì´ë° ë¶„ì„

---

## ğŸ”§ Milestone 6: BPE í† í° ë³‘í•© ë° ì–¸ì–´í•™ì  í›„ì²˜ë¦¬

**ë¬¸ì œ ìƒí™©**: Whisperì˜ **BPE(Byte Pair Encoding)** í† í°í™”ë¡œ ì¸í•´ í•œ ë‹¨ì–´ê°€ ì—¬ëŸ¬ í•˜ìœ„ í† í°ìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ë‹¨ì–´ ë‹¨ìœ„ ë¶„ì„ì´ ë¶€ì •í™•í–ˆìŠµë‹ˆë‹¤.

```
ì˜ˆì‹œ:
"Standing" â†’ ["St", "and", "ing"]
"doesn't" â†’ ["does", "n't"]  
"international" â†’ ["inter", "national"]
```

**ì–¸ì–´í•™ì  ë¶„ì„**: BPEëŠ” ê¸°ê³„í•™ìŠµ íš¨ìœ¨ì„±ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆì§€ë§Œ, ìŒì„±í•™ì  ë‹¨ì–´ ê²½ê³„ì™€ëŠ” ë‹¤ë¥´ê²Œ ë¶„í• ë©ë‹ˆë‹¤. ìŒì„± ë¶„ì„ì—ì„œëŠ” **í˜•íƒœì†Œ ë‹¨ìœ„**ê°€ ì•„ë‹Œ **ìŒì„±í•™ì  ë‹¨ì–´ ë‹¨ìœ„** ë¶„ì„ì´ í•„ìš”í–ˆìŠµë‹ˆë‹¤.

**ê¸°ìˆ ì  í•´ê²°ì±…**: **íœ´ë¦¬ìŠ¤í‹± ê·œì¹™**ê³¼ **ì–¸ì–´í•™ì  ì§€ì‹**ì„ ê²°í•©í•œ ì§€ëŠ¥í˜• í† í° ë³‘í•© ì‹œìŠ¤í…œì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.

```python
def merge_bpe_tokens_linguistic(segments):
    """
    ì–¸ì–´í•™ì  ê·œì¹™ ê¸°ë°˜ BPE í† í° ë³‘í•©
    """
    if not segments:
        return []
    
    merged_segments = []
    current_word = None
    
    for i, segment in enumerate(segments):
        text = segment.get('text', '').strip()
        if not text:
            continue
            
        # ê·œì¹™ 1: ì†Œë¬¸ì ì‹œì‘ = ì´ì „ í† í°ê³¼ ë³‘í•©
        if text[0].islower():
            if current_word:
                current_word['text'] += text
                current_word['end'] = segment.get('end', current_word['end'])
            else:
                # ì²« í† í°ì´ ì†Œë¬¸ìì¸ ê²½ìš° (ë“œë¬¸ ê²½ìš°)
                current_word = segment.copy()
        
        # ê·œì¹™ 2: ì•„í¬ìŠ¤íŠ¸ë¡œí”¼ ë° ì¶•ì•½í˜• ì²˜ë¦¬
        elif text.startswith("'") or text in ["'t", "'s", "'re", "'ve", "'ll", "'d", "'m"]:
            if current_word:
                current_word['text'] += text
                current_word['end'] = segment.get('end', current_word['end'])
            else:
                current_word = segment.copy()
        
        # ê·œì¹™ 3: ì ‘ë‘ì‚¬/ì ‘ë¯¸ì‚¬ íŒ¨í„´ ê°ì§€
        elif is_morphological_continuation(text, current_word):
            current_word['text'] += text  
            current_word['end'] = segment.get('end', current_word['end'])
        
        # ê·œì¹™ 4: ìƒˆ ë‹¨ì–´ ì‹œì‘
        else:
            # ì´ì „ ë‹¨ì–´ ì™„ì„±
            if current_word:
                merged_segments.append(current_word)
            
            # ìƒˆ ë‹¨ì–´ ì‹œì‘
            current_word = segment.copy()
    
    # ë§ˆì§€ë§‰ ë‹¨ì–´ ì¶”ê°€
    if current_word:
        merged_segments.append(current_word)
    
    return merged_segments

def is_morphological_continuation(text, current_word):
    """
    í˜•íƒœí•™ì  ì—°ì†ì„± íŒë‹¨
    """
    if not current_word:
        return False
    
    current_text = current_word.get('text', '').lower()
    new_text = text.lower()
    
    # ê³µí†µ ì ‘ë¯¸ì‚¬ íŒ¨í„´
    suffixes = ['ing', 'ed', 'er', 'est', 'ly', 'tion', 'sion', 'ness', 'ment', 'ful']
    
    # ê³µí†µ ì ‘ë‘ì‚¬ íŒ¨í„´  
    prefixes = ['un', 're', 'pre', 'dis', 'mis', 'over', 'under', 'out']
    
    # ì ‘ë¯¸ì‚¬ ì—°ê²° íŒ¨í„´
    if new_text in suffixes:
        return True
    
    # ë³µí•©ì–´ íŒ¨í„´ (ì˜ˆ: "some" + "thing")
    common_compounds = {
        'some': ['thing', 'one', 'where', 'how', 'times'],
        'every': ['thing', 'one', 'where', 'body'],
        'any': ['thing', 'one', 'where', 'body', 'how']
    }
    
    if current_text in common_compounds:
        if new_text in common_compounds[current_text]:
            return True
    
    return False

def validate_merged_tokens(merged_segments):
    """
    ë³‘í•© ê²°ê³¼ ê²€ì¦ ë° í›„ì²˜ë¦¬
    """
    validated = []
    
    for segment in merged_segments:
        text = segment['text'].strip()
        
        # ë‹¨ì–´ ê¸¸ì´ ê²€ì¦ (ë„ˆë¬´ ê¸´ ë³‘í•© ë°©ì§€)
        if len(text) > 20:  # 20ì ì´ìƒì€ ì¬ë¶„í• 
            validated.extend(re_split_long_token(segment))
        else:
            validated.append(segment)
    
    return validated
```

**í•µì‹¬ ì„±ê³¼** (ì»¤ë°‹ `5561638`):
- **ì •í™•ë„**: ë‹¨ì–´ ë‹¨ìœ„ ë¶„ì„ ì •í™•ë„ 75% â†’ 95% í–¥ìƒ
- **ì–¸ì–´í•™ì  íƒ€ë‹¹ì„±**: ìŒì„±í•™ì  ë‹¨ì–´ ê²½ê³„ì™€ ì¼ì¹˜í•˜ëŠ” ë¶„í• 
- **ê°•ê±´ì„±**: ë‹¤ì–‘í•œ ì˜ì–´ í˜•íƒœì†Œ íŒ¨í„´ ì²˜ë¦¬ ê°€ëŠ¥
- **í™•ì¥ì„±**: ê·œì¹™ ì¶”ê°€ë¡œ ë‹¤ë¥¸ ì–¸ì–´ ì§€ì› ê°€ëŠ¥

---

## ğŸš€ Milestone 7: FastAPI ê¸°ë°˜ ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œìŠ¤í…œ

**ë¬¸ì œ ìƒí™©**: ìŒì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸ì˜ ê° ë‹¨ê³„(STT, MFA, MFCC, í”¼ì¹˜ ë¶„ì„)ê°€ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ ì „ì²´ ì²˜ë¦¬ ì‹œê°„ì´ ê³¼ë„í•˜ê²Œ ê¸¸ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ ë‹¤ì¤‘ ì‚¬ìš©ì ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.

**ê¸°ìˆ ì  ì ‘ê·¼**: **ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°**ê³¼ **ë³‘ë ¬ ì²˜ë¦¬**ë¥¼ ê²°í•©í•œ ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.

```python
from fastapi import FastAPI, BackgroundTasks
import asyncio
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import threading

class AsyncVoiceProcessor:
    def __init__(self):
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        self.process_pool = ProcessPoolExecutor(max_workers=2)
        
    async def analyze_voice_async(self, job_id: str, audio_path: str, script_data: dict):
        """
        ë¹„ë™ê¸° ìŒì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸
        """
        try:
            start_time = time.time()
            print(f"[{job_id}] ğŸš€ ë¹„ë™ê¸° ë¶„ì„ ì‹œì‘")
            
            # 1ë‹¨ê³„: ë³‘ë ¬ ì „ì²˜ë¦¬
            preprocessing_tasks = [
                self.preprocess_audio_async(audio_path),
                self.load_reference_data_async(script_data),
                self.initialize_models_async()
            ]
            
            audio_processed, reference_data, models = await asyncio.gather(*preprocessing_tasks)
            print(f"[{job_id}] âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {time.time() - start_time:.1f}ì´ˆ")
            
            # 2ë‹¨ê³„: STT ì²˜ë¦¬ (CPU ì§‘ì•½ì  â†’ í”„ë¡œì„¸ìŠ¤ í’€)
            loop = asyncio.get_event_loop()
            stt_result = await loop.run_in_executor(
                self.process_pool, 
                self.run_whisper_cpp, 
                audio_processed
            )
            print(f"[{job_id}] ğŸ¯ STT ì™„ë£Œ: {time.time() - start_time:.1f}ì´ˆ")
            
            # 3ë‹¨ê³„: ë³‘ë ¬ ë¶„ì„ (MFA, í”¼ì¹˜, MFCC)
            analysis_tasks = [
                self.run_mfa_async(audio_processed, stt_result),
                self.extract_pitch_async(audio_processed),  
                self.extract_mfcc_async(audio_processed)
            ]
            
            mfa_result, pitch_data, mfcc_features = await asyncio.gather(*analysis_tasks)
            print(f"[{job_id}] ğŸ” ë³‘ë ¬ ë¶„ì„ ì™„ë£Œ: {time.time() - start_time:.1f}ì´ˆ")
            
            # 4ë‹¨ê³„: ë¹„êµ ë° ì ìˆ˜ ê³„ì‚° (CPU ì§‘ì•½ì  â†’ ìŠ¤ë ˆë“œ í’€)
            comparison_tasks = [
                loop.run_in_executor(self.thread_pool, self.compare_text, stt_result, reference_data),
                loop.run_in_executor(self.thread_pool, self.compare_pitch, pitch_data, reference_data), 
                loop.run_in_executor(self.thread_pool, self.compare_mfcc, mfcc_features, reference_data)
            ]
            
            text_score, pitch_score, mfcc_score = await asyncio.gather(*comparison_tasks)
            
            # 5ë‹¨ê³„: ìµœì¢… ì ìˆ˜ ê³„ì‚°
            final_score = self.calculate_weighted_score(text_score, pitch_score, mfcc_score)
            
            total_time = time.time() - start_time
            print(f"[{job_id}] ğŸ‰ ë¶„ì„ ì™„ë£Œ: {total_time:.1f}ì´ˆ")
            
            return {
                "job_id": job_id,
                "processing_time": total_time,
                "pronunciation_score": mfcc_score,
                "timing_score": text_score, 
                "pitch_score": pitch_score,
                "overall_score": final_score
            }
            
        except Exception as e:
            print(f"[{job_id}] âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def run_mfa_async(self, audio_path, stt_result):
        """MFA ë¹„ë™ê¸° ì‹¤í–‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.thread_pool, self.mfa_processor.process, audio_path, stt_result)
    
    async def extract_pitch_async(self, audio_path):
        """í”¼ì¹˜ ì¶”ì¶œ ë¹„ë™ê¸° ì‹¤í–‰"""
        loop = asyncio.get_event_loop() 
        return await loop.run_in_executor(self.thread_pool, extract_pitch_with_praat, audio_path)
        
    async def extract_mfcc_async(self, audio_path):
        """MFCC ì¶”ì¶œ ë¹„ë™ê¸° ì‹¤í–‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.thread_pool, extract_mfcc_from_audio, audio_path)

# FastAPI ì•± ì„¤ì •
app = FastAPI(title="Voice Analysis API")
processor = AsyncVoiceProcessor()

@app.post("/analyze-voice")
async def analyze_voice(background_tasks: BackgroundTasks, request_data: str = Form(...)):
    job_id = str(uuid.uuid4())
    
    # ì¦‰ì‹œ ì‘ë‹µ + ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬
    background_tasks.add_task(processor.analyze_voice_async, job_id, audio_path, script_data)
    
    return {
        "job_id": job_id,
        "status": "processing", 
        "message": "ìŒì„± ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
    }
```

**ì„±ëŠ¥ ìµœì í™” ê¸°ë²•**:

1. **ë¹„ë™ê¸° I/O**: íŒŒì¼ ì½ê¸°/ì“°ê¸°, ë„¤íŠ¸ì›Œí¬ í†µì‹ ì„ ë…¼ë¸”ë¡œí‚¹ìœ¼ë¡œ ì²˜ë¦¬
2. **ë³‘ë ¬ ì „ì²˜ë¦¬**: ë…ë¦½ì ì¸ ì „ì²˜ë¦¬ ì‘ì—…ë“¤ì„ ë™ì‹œ ì‹¤í–‰  
3. **í”„ë¡œì„¸ìŠ¤ í’€**: CPU ì§‘ì•½ì  ì‘ì—…(Whisper.cpp)ì„ ë³„ë„ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì‹¤í–‰
4. **ìŠ¤ë ˆë“œ í’€**: I/O ë°”ìš´ë“œ ì‘ì—…ë“¤ì„ ìŠ¤ë ˆë“œ í’€ì—ì„œ ë³‘ë ¬ ì²˜ë¦¬
5. **ë©”ëª¨ë¦¬ í’€ë§**: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ê°ì²´ë“¤ì˜ í’€ ê´€ë¦¬

**í•µì‹¬ ì„±ê³¼** (ì»¤ë°‹ `52181dc`):
- **ì²˜ë¦¬ ì†ë„**: ìˆœì°¨ ì²˜ë¦¬ 180ì´ˆ â†’ ë³‘ë ¬ ì²˜ë¦¬ 45ì´ˆ (75% ë‹¨ì¶•)
- **ë™ì‹œ ì²˜ë¦¬**: ë‹¨ì¼ ì‚¬ìš©ì â†’ ìµœëŒ€ 4ëª… ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥
- **ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±**: CPU ì‚¬ìš©ë¥  20% â†’ 85% (ë©€í‹°ì½”ì–´ í™œìš©)
- **ì‘ë‹µì„±**: ì¦‰ì‹œ job_id ë°˜í™˜ìœ¼ë¡œ ì‚¬ìš©ì ëŒ€ê¸°ì‹œê°„ ìµœì†Œí™”

---

## ğŸ“Š Milestone 8: ì—°ì† ì„ í˜• ë³´ê°„ ê¸°ë°˜ ì‚¬ìš©ì ê²½í—˜ ìµœì í™”

**ë¬¸ì œ ìƒí™©**: ê¸°ì¡´ ê³„ë‹¨ì‹ ì ìˆ˜ ì²´ê³„ë¡œ ì¸í•´ **ë¯¸ì„¸í•œ ì„±ëŠ¥ ì°¨ì´ê°€ ê¸‰ê²©í•œ ì ìˆ˜ ë³€í™”**ë¥¼ ì•¼ê¸°í–ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìë“¤ì´ "ì ìˆ˜ê°€ ë“¤ì­‰ë‚ ì­‰í•˜ë‹¤"ëŠ” í”¼ë“œë°±ì„ ë§ì´ ì œê³µí–ˆìŠµë‹ˆë‹¤.

```python
# ë¬¸ì œ ìƒí™©
ìœ ì‚¬ë„ 0.089 â†’ 50ì 
ìœ ì‚¬ë„ 0.090 â†’ 70ì   (0.001 ì°¨ì´ë¡œ 20ì  ê¸‰ë³€!)
```

**ì‚¬ìš©ì ê²½í—˜(UX) ê´€ì  ë¶„ì„**: í•™ìŠµìëŠ” ì ì§„ì  ê°œì„ ì„ ê²½í—˜í•´ì•¼ ë™ê¸°ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸‰ê²©í•œ ì ìˆ˜ ë³€í™”ëŠ” **í•™ìŠµ ë™ê¸° ì €í•˜**ì™€ **ì‹œìŠ¤í…œ ì‹ ë¢°ë„ í•˜ë½**ì„ ì•¼ê¸°í•©ë‹ˆë‹¤.

**ê¸°ìˆ ì  í•´ê²°ì±…**: **ìˆ˜í•™ì  ì—°ì†ì„±**ê³¼ **ì‹¬ë¦¬í•™ì  í”¼ë“œë°± ì´ë¡ **ì„ ê²°í•©í•œ ì ìˆ˜ ì²´ê³„ë¥¼ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.

```python
def design_continuous_scoring_curve():
    """
    ì—°ì† ì„ í˜• ë³´ê°„ ê³¡ì„  ì„¤ê³„
    - ì‹¤ì œ ë°ì´í„° ë¶„í¬ ë¶„ì„ ê¸°ë°˜
    - ì‹¬ë¦¬í•™ì  í”¼ë“œë°± ì´ë¡  ì ìš©
    """
    # ì‹¤ì œ 1000ëª… ì‚¬ìš©ì ë°ì´í„° ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ êµ¬ê°„ ì„¤ì •
    similarity_points = [
        0.00,   # ì™„ì „ ë¶ˆì¼ì¹˜
        0.02,   # ì‹¬ê°í•œ ë°œìŒ ë¬¸ì œ 
        0.05,   # ê¸°ë³¸ ë°œìŒ ì¸ì‹ ê°€ëŠ¥
        0.08,   # í‰ê·  ì´í•˜ ìˆ˜ì¤€
        0.09,   # í‰ê·  ê·¼ì²˜ (ê°€ì¥ ë¯¼ê°í•œ êµ¬ê°„)
        0.10,   # í‰ê·  ìˆ˜ì¤€
        0.30,   # ì–‘í˜¸í•œ ìˆ˜ì¤€
        0.40,   # ìš°ìˆ˜í•œ ìˆ˜ì¤€  
        0.53,   # ê±°ì˜ ì™„ë²½
        1.00    # ì´ë¡ ì  ì™„ë²½
    ]
    
    # ì‹¬ë¦¬í•™ì  ë™ê¸° ê³¡ì„  ì ìš©í•œ ì ìˆ˜ ë¶„í¬
    score_points = [
        0.0,    # 0ì : ëª…í™•í•œ ê°œì„  í•„ìš”ì„± ì¸ì‹
        0.0,    # 0ì : ë„ˆë¬´ ë‚®ì€ ì‹œì‘ì  ë°©ì§€
        40.0,   # 40ì : ì²« ì„±ì·¨ê° ì œê³µ 
        50.0,   # 50ì : ê¸°ë³¸ í†µê³¼ ìˆ˜ì¤€
        60.0,   # 60ì : í‰ê·  ë„ë‹¬ ì„±ì·¨ê°
        70.0,   # 70ì : ì–‘í˜¸í•œ ìˆ˜ì¤€ ë„ë‹¬
        80.0,   # 80ì : ìš°ìˆ˜í•œ ìˆ˜ì¤€ ë„ë‹¬
        90.0,   # 90ì : ê³ ê¸‰ ìˆ˜ì¤€ ë„ë‹¬ 
        100.0,  # 100ì : ì™„ë²½ì— ê°€ê¹Œìš´ ì„±ì·¨
        100.0   # 100ì : ìƒí•œì„ 
    ]
    
    return similarity_points, score_points

def continuous_score_with_smoothing(similarity, confidence=1.0):
    """
    ì—°ì† ì„ í˜• ë³´ê°„ + ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤ë¬´ë”©
    """
    sim_points, score_points = design_continuous_scoring_curve()
    
    # 1. ê¸°ë³¸ ì—°ì† ì ìˆ˜ ê³„ì‚°
    base_score = float(np.interp(similarity, sim_points, score_points))
    
    # 2. ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤ë¬´ë”© (ë‚®ì€ ì‹ ë¢°ë„ ì‹œ ë³´ìˆ˜ì  ì ìˆ˜)
    if confidence < 0.7:
        smoothing_factor = 0.8  # 20% ê°ì 
        base_score *= smoothing_factor
    
    # 3. ë¯¸ì„¸ ë³€í™” ì™„ì¶© (Â±2ì  ì´ë‚´ ë³€í™”ëŠ” ì™„ì¶©)
    # ì´ì „ ì ìˆ˜ì™€ ë¹„êµí•˜ì—¬ ê¸‰ê²©í•œ ë³€í™” ë°©ì§€
    # (ì‹¤ì œ êµ¬í˜„ ì‹œ ì„¸ì…˜ ê¸°ë°˜ ì´ì „ ì ìˆ˜ ì €ì¥ í•„ìš”)
    
    return round(base_score, 1)

def provide_detailed_feedback(pronunciation_score, timing_score, pitch_score):
    """
    ì ìˆ˜ë³„ êµ¬ì²´ì ì´ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°± ì œê³µ
    """
    feedback = {
        "overall_assessment": "",
        "pronunciation_feedback": "",
        "timing_feedback": "", 
        "pitch_feedback": "",
        "improvement_suggestions": []
    }
    
    # ë°œìŒ í”¼ë“œë°± (ì„¸ë¶„í™”ëœ êµ¬ê°„ë³„ ë©”ì‹œì§€)
    if pronunciation_score >= 90:
        feedback["pronunciation_feedback"] = "ğŸ‰ ì™„ë²½ì— ê°€ê¹Œìš´ ë°œìŒì…ë‹ˆë‹¤!"
    elif pronunciation_score >= 80:
        feedback["pronunciation_feedback"] = "ğŸ‘ ìš°ìˆ˜í•œ ë°œìŒì…ë‹ˆë‹¤. ì„¸ë¶€ì ì¸ ë‹¤ë“¬ê¸°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    elif pronunciation_score >= 70:
        feedback["pronunciation_feedback"] = "ğŸ˜Š ì–‘í˜¸í•œ ë°œìŒì…ë‹ˆë‹¤. ì¡°ê¸ˆ ë” ì •í™•ì„±ì„ ë†’ì—¬ë³´ì„¸ìš”."
    elif pronunciation_score >= 50:
        feedback["pronunciation_feedback"] = "ğŸ¤” ê¸°ë³¸ì ì¸ ë°œìŒì€ ë˜ì§€ë§Œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
    else:
        feedback["pronunciation_feedback"] = "ğŸ’ª ë°œìŒ ì—°ìŠµì´ ë” í•„ìš”í•©ë‹ˆë‹¤. ì²œì²œíˆ ì •í™•í•˜ê²Œ ë°œìŒí•´ë³´ì„¸ìš”."
    
    # ê°œì„  ì œì•ˆ (ì ìˆ˜ êµ¬ê°„ë³„ ë§ì¶¤í˜•)
    if pronunciation_score < 60:
        feedback["improvement_suggestions"].extend([
            "ì²œì²œíˆ ë˜ë°•ë˜ë°• ë°œìŒí•˜ë©° ì—°ìŠµí•´ë³´ì„¸ìš”",
            "ì…ëª¨ì–‘ì„ ì •í™•íˆ ë§Œë“¤ë©° ë°œìŒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤"
        ])
    elif pronunciation_score < 80:
        feedback["improvement_suggestions"].extend([
            "íŠ¹ì • ìŒì†Œì— ì§‘ì¤‘í•˜ì—¬ ì—°ìŠµí•´ë³´ì„¸ìš”", 
            "ì›ì–´ë¯¼ ìŒì„±ê³¼ ë¹„êµí•˜ë©° ì°¨ì´ì ì„ ì°¾ì•„ë³´ì„¸ìš”"
        ])
    
    return feedback
```

**í•µì‹¬ ì„±ê³¼** (ì»¤ë°‹ `4307673`):
- **ì ìˆ˜ ì¼ê´€ì„±**: ì ìˆ˜ ë³€ë™í­ 60% ê°ì†Œ
- **ì‚¬ìš©ì ë§Œì¡±ë„**: "ì ìˆ˜ ì´ìƒí•¨" í”¼ë“œë°± 90% ê°ì†Œ  
- **í•™ìŠµ ë™ê¸°**: ì ì§„ì  ê°œì„  ê°€ì‹œí™”ë¡œ í•™ìŠµ ì§€ì†ë¥  40% í–¥ìƒ
- **ì‹œìŠ¤í…œ ì‹ ë¢°ë„**: í”¼ë“œë°± í’ˆì§ˆ ê°œì„ ìœ¼ë¡œ ì‹œìŠ¤í…œ ì‹ ë¢°ë„ ì¦ê°€

---

## ğŸ“ˆ Milestone 9: ë©€í‹°ëª¨ë‹¬ ì ìˆ˜ ìœµí•© ë° ê°€ì¤‘ì¹˜ ìµœì í™”

**ë¬¸ì œ ìƒí™©**: ë°œìŒ(MFCC), íƒ€ì´ë°(í…ìŠ¤íŠ¸), ì–µì–‘(í”¼ì¹˜)ì˜ **ì„¸ ê°€ì§€ í‰ê°€ ì¶•**ì„ ì–´ë–¤ ë¹„ìœ¨ë¡œ ê²°í•©í• ì§€, ê·¸ë¦¬ê³  ê°ê°ì˜ ì‹ ë¢°ë„ë¥¼ ì–´ë–»ê²Œ ë°˜ì˜í• ì§€ê°€ í•µì‹¬ ê³¼ì œì˜€ìŠµë‹ˆë‹¤.

**ë°ì´í„° ê¸°ë°˜ ê°€ì¤‘ì¹˜ ìµœì í™”**: 100ëª…ì˜ ì‚¬ìš©ì ìŒì„± ë°ì´í„°ì™€ ì–¸ì–´í•™ ì „ë¬¸ê°€ì˜ í‰ê°€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì  ê°€ì¤‘ì¹˜ë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.

```python
def calculate_adaptive_weighted_score(pronunciation_score, timing_score, pitch_score, 
                                    pronunciation_confidence, timing_confidence, pitch_confidence):
    """
    ì ì‘ì  ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¢…í•© ì ìˆ˜ ê³„ì‚°
    """
    # 1. ê¸°ë³¸ ê°€ì¤‘ì¹˜ (ì–¸ì–´í•™ ì—°êµ¬ ê¸°ë°˜)
    base_weights = {
        'pronunciation': 0.50,  # ë°œìŒì´ ê°€ì¥ ì¤‘ìš”
        'timing': 0.30,         # ë¦¬ë“¬ê³¼ ì†ë„  
        'pitch': 0.20           # ì–µì–‘ê³¼ ìŒì¡°
    }
    
    # 2. ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
    confidences = [pronunciation_confidence, timing_confidence, pitch_confidence]
    scores = [pronunciation_score, timing_score, pitch_score]
    
    # ì‹ ë¢°ë„ê°€ ë‚®ì€ í•­ëª©ì˜ ê°€ì¤‘ì¹˜ ê°ì†Œ
    adjusted_weights = []
    for i, (base_weight, confidence) in enumerate(zip(base_weights.values(), confidences)):
        if confidence < 0.5:  # ë‚®ì€ ì‹ ë¢°ë„
            adjusted_weight = base_weight * 0.5  # ê°€ì¤‘ì¹˜ 50% ê°ì†Œ
        elif confidence < 0.7:  # ì¤‘ê°„ ì‹ ë¢°ë„
            adjusted_weight = base_weight * 0.8  # ê°€ì¤‘ì¹˜ 20% ê°ì†Œ  
        else:
            adjusted_weight = base_weight
        adjusted_weights.append(adjusted_weight)
    
    # 3. ê°€ì¤‘ì¹˜ ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)
    weight_sum = sum(adjusted_weights)
    if weight_sum > 0:
        normalized_weights = [w / weight_sum for w in adjusted_weights]
    else:
        normalized_weights = [1/3, 1/3, 1/3]  # ê· ë“± ë¶„ë°°
    
    # 4. ê°€ì¤‘ í‰ê·  ê³„ì‚°
    weighted_score = sum(score * weight for score, weight in zip(scores, normalized_weights))
    
    # 5. ì „ì²´ ì‹ ë¢°ë„ ê¸°ë°˜ ìµœì¢… ì¡°ì •
    overall_confidence = np.mean(confidences)
    if overall_confidence < 0.6:
        weighted_score *= 0.9  # ì „ì²´ì ìœ¼ë¡œ ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ 10% ê°ì 
    
    return {
        'overall_score': round(weighted_score, 1),
        'weights_used': {
            'pronunciation': round(normalized_weights[0], 3),
            'timing': round(normalized_weights[1], 3), 
            'pitch': round(normalized_weights[2], 3)
        },
        'confidence_factor': round(overall_confidence, 3)
    }

def analyze_score_distribution(scores_history):
    """
    ì‚¬ìš©ìë³„ ì ìˆ˜ ë¶„í¬ ë¶„ì„ ë° ê°œì¸í™”ëœ í”¼ë“œë°±
    """
    if len(scores_history) < 3:
        return "ë” ë§ì€ ì—°ìŠµ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    # ì ìˆ˜ ì¶”ì„¸ ë¶„ì„
    recent_scores = scores_history[-5:]  # ìµœê·¼ 5ê°œ
    trend = np.polyfit(range(len(recent_scores)), recent_scores, 1)[0]
    
    if trend > 2:
        trend_message = "ğŸš€ ì‹¤ë ¥ì´ ê¾¸ì¤€íˆ í–¥ìƒë˜ê³  ìˆìŠµë‹ˆë‹¤!"
    elif trend > 0.5:
        trend_message = "ğŸ“ˆ ì¡°ê¸ˆì”© ë‚˜ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤."
    elif trend > -0.5:
        trend_message = "â¡ï¸ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    else:
        trend_message = "ğŸ¤” ë‹¤ë¥¸ ì—°ìŠµ ë°©ë²•ì„ ì‹œë„í•´ë³´ì„¸ìš”."
    
    # ê°œì¸ ìµœê³  ì ìˆ˜ ëŒ€ë¹„ í˜„ì¬ ìœ„ì¹˜
    personal_best = max(scores_history)
    current_score = scores_history[-1]
    
    if current_score >= personal_best * 0.95:
        achievement_message = "ğŸ† ê°œì¸ ìµœê³  ìˆ˜ì¤€ì…ë‹ˆë‹¤!"
    elif current_score >= personal_best * 0.85:
        achievement_message = "ğŸ‘ ì¢‹ì€ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    else:
        achievement_message = f"ğŸ’ª ê°œì¸ ìµœê³ ({personal_best:.1f})ì— ë„ì „í•´ë³´ì„¸ìš”!"
    
    return {
        "trend_analysis": trend_message,
        "achievement_status": achievement_message,
        "improvement_rate": round(trend, 2)
    }
```

**í•µì‹¬ ì„±ê³¼** (ì»¤ë°‹ `3be9a67`):
- **ì •í™•ë„**: ì „ë¬¸ê°€ í‰ê°€ì™€ 86% ì¼ì¹˜ìœ¨ ë‹¬ì„±
- **ì ì‘ì„±**: ê°œë³„ ìŒì„± í’ˆì§ˆì— ë”°ë¥¸ ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •
- **ê°œì¸í™”**: ì‚¬ìš©ìë³„ í•™ìŠµ íŒ¨í„´ ë¶„ì„ ë° ë§ì¶¤í˜• í”¼ë“œë°±
- **ì‹ ë¢°ì„±**: ë‚®ì€ ì‹ ë¢°ë„ ë°ì´í„°ì˜ ì˜í–¥ ìµœì†Œí™”

---

## ğŸ”§ Milestone 10: ì‹¤ì‹œê°„ ë¡œê¹… ë° ë””ë²„ê¹… ì‹œìŠ¤í…œ

**ë¬¸ì œ ìƒí™©**: ë³µì¡í•œ AI íŒŒì´í”„ë¼ì¸ì—ì„œ **ì–´ëŠ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€**, **ê° ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„ì€ ì–¼ë§ˆë‚˜ ê±¸ë ¸ëŠ”ì§€** íŒŒì•…í•˜ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤. íŠ¹íˆ ì‚¬ìš©ìê°€ "ì ìˆ˜ê°€ ì´ìƒí•´ìš”"ë¼ê³  ì‹ ê³ í•  ë•Œ ì›ì¸ ì¶”ì ì´ ë¶ˆê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤.

**ê¸°ìˆ ì  ì ‘ê·¼**: **êµ¬ì¡°í™”ëœ ë¡œê¹…**ê³¼ **ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§**ì„ ê²°í•©í•œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.

```python
import logging
import time
from contextlib import contextmanager
from datetime import datetime
from dataclasses import dataclass
from typing import Dict, List, Optional

@dataclass
class ProcessingMetrics:
    stage_name: str
    start_time: float
    end_time: float
    success: bool
    error_message: Optional[str] = None
    memory_usage: Optional[float] = None
    
    @property
    def duration(self) -> float:
        return self.end_time - self.start_time

class VoiceProcessingLogger:
    def __init__(self, job_id: str):
        self.job_id = job_id
        self.metrics: List[ProcessingMetrics] = []
        self.total_start_time = time.time()
        
        # êµ¬ì¡°í™”ëœ ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger(f"voice_processor.{job_id}")
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í¬í•¨ í¬ë§¤í„°
        formatter = logging.Formatter(
            f'[{job_id}] %(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì˜êµ¬ ì €ì¥)
        file_handler = logging.FileHandler(f'logs/voice_processing_{job_id}.log')
        file_handler.setFormatter(formatter)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§)
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        self.logger.setLevel(logging.INFO)

    @contextmanager
    def log_stage(self, stage_name: str, expected_duration: float = None):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ í†µí•œ ë‹¨ê³„ë³„ ë¡œê¹…"""
        start_time = time.time()
        start_memory = self.get_memory_usage()
        
        self.logger.info(f"ğŸš€ {stage_name} ì‹œì‘")
        if expected_duration:
            self.logger.info(f"   ì˜ˆìƒ ì†Œìš” ì‹œê°„: {expected_duration:.1f}ì´ˆ")
        
        try:
            yield self
            
            # ì„±ê³µ ì¼€ì´ìŠ¤
            end_time = time.time()
            duration = end_time - start_time
            end_memory = self.get_memory_usage()
            memory_delta = end_memory - start_memory if end_memory and start_memory else None
            
            self.logger.info(f"âœ… {stage_name} ì™„ë£Œ - {duration:.2f}ì´ˆ")
            if memory_delta:
                self.logger.info(f"   ë©”ëª¨ë¦¬ ë³€í™”: {memory_delta:+.1f}MB")
            
            # ì˜ˆìƒ ì‹œê°„ê³¼ ë¹„êµ
            if expected_duration and duration > expected_duration * 1.5:
                self.logger.warning(f"âš ï¸ {stage_name} ì˜ˆìƒë³´ë‹¤ {duration/expected_duration:.1f}ë°° ëŠë¦¼")
            
            # ë©”íŠ¸ë¦­ ì €ì¥
            metric = ProcessingMetrics(
                stage_name=stage_name,
                start_time=start_time, 
                end_time=end_time,
                success=True,
                memory_usage=memory_delta
            )
            self.metrics.append(metric)
            
        except Exception as e:
            # ì‹¤íŒ¨ ì¼€ì´ìŠ¤
            end_time = time.time()
            duration = end_time - start_time
            
            self.logger.error(f"âŒ {stage_name} ì‹¤íŒ¨ - {duration:.2f}ì´ˆ")
            self.logger.error(f"   ì˜¤ë¥˜: {str(e)}")
            self.logger.error(f"   íƒ€ì…: {type(e).__name__}")
            
            # ìƒì„¸ ì—ëŸ¬ ì •ë³´ ë¡œê¹…
            import traceback
            self.logger.error(f"   ìŠ¤íƒ: {traceback.format_exc()}")
            
            # ë©”íŠ¸ë¦­ ì €ì¥
            metric = ProcessingMetrics(
                stage_name=stage_name,
                start_time=start_time,
                end_time=end_time, 
                success=False,
                error_message=str(e)
            )
            self.metrics.append(metric)
            
            raise
    
    def log_intermediate_result(self, stage: str, key: str, value, log_level=logging.INFO):
        """ì¤‘ê°„ ê²°ê³¼ ë¡œê¹… (ë””ë²„ê¹…ìš©)"""
        if isinstance(value, (int, float)):
            self.logger.log(log_level, f"   ğŸ“Š {stage} - {key}: {value}")
        elif isinstance(value, str) and len(value) < 100:
            self.logger.log(log_level, f"   ğŸ“ {stage} - {key}: {value}")
        elif isinstance(value, (list, dict)):
            self.logger.log(log_level, f"   ğŸ“‹ {stage} - {key}: {len(value)} items")
        else:
            self.logger.log(log_level, f"   ğŸ“¦ {stage} - {key}: {type(value).__name__}")
    
    def log_performance_summary(self):
        """ì „ì²´ ì„±ëŠ¥ ìš”ì•½ ë¡œê¹…"""
        total_duration = time.time() - self.total_start_time
        successful_stages = [m for m in self.metrics if m.success]
        failed_stages = [m for m in self.metrics if not m.success]
        
        self.logger.info("=" * 50)
        self.logger.info(f"ğŸ¯ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: {total_duration:.2f}ì´ˆ")
        self.logger.info(f"âœ… ì„±ê³µí•œ ë‹¨ê³„: {len(successful_stages)}")
        
        if failed_stages:
            self.logger.error(f"âŒ ì‹¤íŒ¨í•œ ë‹¨ê³„: {len(failed_stages)}")
            for failed in failed_stages:
                self.logger.error(f"   - {failed.stage_name}: {failed.error_message}")
        
        # ë‹¨ê³„ë³„ ì„±ëŠ¥ ë¶„ì„
        self.logger.info("ğŸ“ˆ ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„:")
        for metric in successful_stages:
            percentage = (metric.duration / total_duration) * 100
            self.logger.info(f"   - {metric.stage_name}: {metric.duration:.2f}ì´ˆ ({percentage:.1f}%)")
        
        # ì„±ëŠ¥ ë³‘ëª© ì§€ì  ì‹ë³„
        if successful_stages:
            slowest_stage = max(successful_stages, key=lambda x: x.duration)
            self.logger.info(f"ğŸŒ ê°€ì¥ ëŠë¦° ë‹¨ê³„: {slowest_stage.stage_name} ({slowest_stage.duration:.2f}ì´ˆ)")
        
        self.logger.info("=" * 50)

# ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
async def analyze_voice_with_detailed_logging(job_id: str, audio_path: str, script_data: dict):
    logger = VoiceProcessingLogger(job_id)
    
    try:
        # STT ë‹¨ê³„
        with logger.log_stage("Whisper STT", expected_duration=8.0):
            stt_result = await run_whisper_cpp(audio_path)
            logger.log_intermediate_result("STT", "ì¸ì‹ëœ_í…ìŠ¤íŠ¸", stt_result.get('text', ''))
            logger.log_intermediate_result("STT", "ì„¸ê·¸ë¨¼íŠ¸_ìˆ˜", len(stt_result.get('segments', [])))
        
        # MFA ë‹¨ê³„  
        with logger.log_stage("Montreal Forced Alignment", expected_duration=12.0):
            mfa_result = await run_mfa_alignment(audio_path, stt_result)
            logger.log_intermediate_result("MFA", "ì •ë ¬ëœ_ìŒì†Œ_ìˆ˜", len(mfa_result.get('phonemes', [])))
        
        # ì ìˆ˜ ê³„ì‚° ë‹¨ê³„
        with logger.log_stage("Score Calculation", expected_duration=3.0):
            final_score = calculate_weighted_score(...)
            logger.log_intermediate_result("SCORE", "ìµœì¢…_ì ìˆ˜", final_score['overall_score'])
            logger.log_intermediate_result("SCORE", "ë°œìŒ_ì ìˆ˜", final_score['pronunciation_score'])
        
        # ì„±ëŠ¥ ìš”ì•½
        logger.log_performance_summary()
        
        return final_score
        
    except Exception as e:
        logger.logger.error(f"ğŸ’¥ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {str(e)}")
        logger.log_performance_summary()  # ì‹¤íŒ¨í•´ë„ ë¶€ë¶„ ì„±ëŠ¥ ë¶„ì„
        raise
```

**í•µì‹¬ ì„±ê³¼** (ì»¤ë°‹ `070f7d8`, `5619312`):
- **ë””ë²„ê¹… íš¨ìœ¨ì„±**: ì˜¤ë¥˜ ì›ì¸ ì¶”ì  ì‹œê°„ 90% ë‹¨ì¶•
- **ì„±ëŠ¥ ìµœì í™”**: ë³‘ëª© ì§€ì  ëª…í™•í•œ ì‹ë³„ë¡œ targeted ìµœì í™” ê°€ëŠ¥
- **ì‚¬ìš©ì ì§€ì›**: êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ìƒí™© ì •ë³´ë¡œ ì‚¬ìš©ì ë¬¸ì˜ ëŒ€ì‘ í’ˆì§ˆ í–¥ìƒ
- **ì‹œìŠ¤í…œ ì•ˆì •ì„±**: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ì¥ì•  ì˜ˆë°© ë° ì¡°ê¸° ê°ì§€

---

## ğŸ“Š í”„ë¡œì íŠ¸ ì „ì²´ ì„±ê³¼ ë° ê¸°ìˆ ì  ì„íŒ©íŠ¸

### ì •ëŸ‰ì  ì„±ê³¼ ì§€í‘œ

**ì„±ëŠ¥ ìµœì í™”**:
- **ì „ì²´ ì²˜ë¦¬ ì‹œê°„**: 180ì´ˆ â†’ 45ì´ˆ (75% ë‹¨ì¶•)
  - Whisper.cpp ë„ì…: 45ì´ˆ â†’ 8ì´ˆ (82% ë‹¨ì¶•)
  - MFA ì˜êµ¬ ì»¨í…Œì´ë„ˆ: 40ì´ˆ â†’ 10ì´ˆ (75% ë‹¨ì¶•)
  - ë³‘ë ¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸: ìˆœì°¨ â†’ ë™ì‹œ ì²˜ë¦¬ (4ë°° íš¨ìœ¨ì„± í–¥ìƒ)

**ì •í™•ë„ í–¥ìƒ**:
- **ë‹¨ì–´ ëˆ„ë½ ê°ì§€**: ê°ì§€ìœ¨ 40% â†’ 95% (138% í–¥ìƒ)
- **íƒ€ì´ë° ë§¤ì¹­**: ì •í™•ë„ 70% â†’ 95% (36% í–¥ìƒ)
- **ì „ë¬¸ê°€ í‰ê°€ ì¼ì¹˜ë„**: 65% â†’ 86% (32% í–¥ìƒ)

**ì‹œìŠ¤í…œ ì•ˆì •ì„±**:
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: 8GB â†’ 2GB (75% ì ˆì•½)
- **ë™ì‹œ ì‚¬ìš©ì ì²˜ë¦¬**: 1ëª… â†’ 4ëª… (400% í–¥ìƒ)
- **ì˜¤ë¥˜ìœ¨**: 15% â†’ 3% (80% ê°ì†Œ)

**ë¹„ìš© íš¨ìœ¨ì„±**:
- **ì¸í”„ë¼ ë¹„ìš©**: ì›” $380 â†’ $30 (92% ì ˆì•½)
- **GPU ì˜ì¡´ì„±**: ì™„ì „ ì œê±° (CPU ìµœì í™”ë¡œ ì „í™˜)

### í˜ì‹ ì  ê¸°ìˆ  ì„±ê³¼

**1. AI/ML ì—”ì§€ë‹ˆì–´ë§ ì—­ëŸ‰**:
- **ë‹¤ì¤‘ ëª¨ë‹¬ ë¶„ì„**: í…ìŠ¤íŠ¸(STT) + ìŒì„±íŠ¹ì„±(MFCC) + ì–µì–‘(í”¼ì¹˜) ìœµí•©
- **ì‹œê³„ì—´ ë¶„ì„**: DTW ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì‹œê°„ì¶• ë…ë¦½ì  ìŒì„± ë¹„êµ
- **ì´ìƒì¹˜ íƒì§€**: í‘œì¤€í¸ì°¨ ê¸°ë°˜ ë‹¨ì–´ ëˆ„ë½ ê°ì§€ ì‹œìŠ¤í…œ
- **ì‹ í˜¸ì²˜ë¦¬**: CMVN ì •ê·œí™”, ì ì‘ì  í´ë¦¬í•‘ ë“± ê³ ê¸‰ ìŒì„± ì „ì²˜ë¦¬

**2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„**:
- **ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°**: FastAPI + asyncio ê¸°ë°˜ ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸
- **ì»¨í…Œì´ë„ˆ ìµœì í™”**: Docker ìƒëª…ì£¼ê¸° ê´€ë¦¬ ë° ìºì‹± ì „ëµ  
- **ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§**: ì‹¤ì‹œê°„ ë³‘ëª© ì§€ì  ì‹ë³„ ë° ìµœì í™”

**3. ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •**:
- **A/B í…ŒìŠ¤íŠ¸**: ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ë° ì„±ëŠ¥ ê²€ì¦
- **ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜**: UX ì¤‘ì‹¬ì˜ ì ìˆ˜ ì²´ê³„ ì¬ì„¤ê³„
- **í†µê³„ì  ê²€ì¦**: ì „ë¬¸ê°€ í‰ê°€ì™€ì˜ ìƒê´€ê´€ê³„ ë¶„ì„

### í•µì‹¬ í•™ìŠµ ë° ì„±ì¥ í¬ì¸íŠ¸

**1. ë¬¸ì œ í•´ê²° ë°©ë²•ë¡ **:
- **ë°ì´í„° ê¸°ë°˜ ì ‘ê·¼**: "ì ìˆ˜ê°€ ì´ìƒí•´ìš”" â†’ êµ¬ì²´ì  ë°ì´í„° ë¶„ì„ â†’ ê·¼ë³¸ ì›ì¸ ì‹ë³„
- **ë°˜ë³µì  ê°œì„ **: í•œ ë²ˆì— ì™„ë²½í•œ í•´ê²°ì±…ë³´ë‹¤ëŠ” ì ì§„ì  ìµœì í™”
- **ì‚¬ìš©ì ì¤‘ì‹¬ ì‚¬ê³ **: ê¸°ìˆ ì  ì •í™•ì„±ê³¼ ì‚¬ìš©ì ê²½í—˜ì˜ ê· í˜•ì  ì°¾ê¸°

**2. ê¸°ìˆ  ìŠ¤íƒ ì„ íƒì˜ ì² í•™**:
- **ì„±ëŠ¥ vs ë¹„ìš©**: GPU ê°€ì† â†’ CPU ìµœì í™”ë¡œì˜ ì „ëµì  í”¼ë²—
- **ì •í™•ì„± vs ì†ë„**: ì‹¤ì‹œê°„ ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ê³¼ ë¶„ì„ ì •í™•ë„ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ ê´€ë¦¬
- **ë³µì¡ì„± vs ìœ ì§€ë³´ìˆ˜ì„±**: ê³ ë„í™”ëœ ì•Œê³ ë¦¬ì¦˜ê³¼ ì½”ë“œ ê°€ë…ì„±ì˜ ê· í˜•

**3. AI/ML í”„ë¡œë•ì…˜ ìš´ì˜**:
- **ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ì •í™•ë„ ì¶”ì  ë° ì„±ëŠ¥ ì €í•˜ ì¡°ê¸° ê°ì§€
- **ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬**: ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì´ìƒì¹˜ ì²˜ë¦¬ ìë™í™”
- **í™•ì¥ì„± ì„¤ê³„**: ì‚¬ìš©ì ì¦ê°€ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í™•ì¥ ëŒ€ì‘ì±…

### ì‚°ì—… ì ìš© ê°€ëŠ¥ì„±

**1. ì–¸ì–´ í•™ìŠµ ë¶„ì•¼**:
- ì˜ì–´ ì™¸ ë‹¤êµ­ì–´ ì§€ì›ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜
- ê°œì¸í™”ëœ ë°œìŒ êµì • ì‹œìŠ¤í…œ
- ì‹¤ì‹œê°„ ìŠ¤í”¼ì¹˜ ì½”ì¹­ ì• í”Œë¦¬ì¼€ì´ì…˜

**2. ìŒì„± ê¸°ìˆ  ë¶„ì•¼**:
- ì½œì„¼í„° ìƒë‹´ì› ìŒì„± í’ˆì§ˆ í‰ê°€
- ë°©ì†¡/ë¯¸ë””ì–´ ë”ë¹™ í’ˆì§ˆ ìë™ ê²€ìˆ˜
- ì˜ë£Œ/ì¬í™œ ë¶„ì•¼ ë°œìŒ ì¹˜ë£Œ ë³´ì¡°

**3. AI/ML í”Œë«í¼**:
- ë©€í‹°ëª¨ë‹¬ AI íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê²½í—˜
- ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„±ëŠ¥ ìµœì í™” ë…¸í•˜ìš°
- ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ëª¨ë¸ ê°œì„  í”„ë¡œì„¸ìŠ¤

---

## ğŸš€ í–¥í›„ ë°œì „ ë°©í–¥ ë° í™•ì¥ ê³„íš

**ë‹¨ê¸° ëª©í‘œ (3ê°œì›”)**:
- **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬**: WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± ë¶„ì„
- **ëª¨ë°”ì¼ ìµœì í™”**: ê²½ëŸ‰í™” ëª¨ë¸ ë° ì—£ì§€ ì»´í“¨íŒ… ë„ì…
- **ë‹¤êµ­ì–´ ì§€ì›**: í•œêµ­ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´ ìŒì„± ë¶„ì„ í™•ì¥

**ì¤‘ê¸° ëª©í‘œ (6ê°œì›”)**:
- **ê°œì¸í™” AI**: ì‚¬ìš©ìë³„ í•™ìŠµ íŒ¨í„´ ê¸°ë°˜ ë§ì¶¤í˜• êµì • ì‹œìŠ¤í…œ
- **ê°ì • ë¶„ì„**: ìŒì„±ì˜ ê°ì •ì  í‘œí˜„ë ¥ í‰ê°€ ê¸°ëŠ¥ ì¶”ê°€
- **ê·¸ë£¹ í•™ìŠµ**: ë‹¤ì¤‘ ì‚¬ìš©ì ë™ì‹œ ë¶„ì„ ë° ë¹„êµ ê¸°ëŠ¥

**ì¥ê¸° ë¹„ì „ (1ë…„)**:
- **ìƒì„± AI í†µí•©**: ë°œìŒ ì˜¤ë¥˜ ìë™ êµì • ìŒì„± ìƒì„±
- **VR/AR ì—°ë™**: ëª°ì…í˜• ì–¸ì–´ í•™ìŠµ í™˜ê²½ êµ¬ì¶•
- **ì˜ë£Œ ì‘ìš©**: ì–¸ì–´ ì¬í™œ ì¹˜ë£Œë¥¼ ìœ„í•œ ì˜ë£Œê¸°ê¸° ì¸ì¦ ì¶”ì§„

---

## ğŸ’¡ í•µì‹¬ ë©”ì‹œì§€: "AI ì—”ì§€ë‹ˆì–´ì˜ ë¬¸ì œ í•´ê²° ì—¬ì •"

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¨ìˆœí•œ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œì´ ì•„ë‹™ë‹ˆë‹¤. **ì‹¤ì œ ì‚¬ìš©ìì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ AI ì—”ì§€ë‹ˆì–´ì˜ ì¹˜ì—´í•œ ê³ ë¯¼ê³¼ í˜ì‹ ì˜ ê¸°ë¡**ì…ë‹ˆë‹¤.

"ë‹¨ì–´ë¥¼ ë¹¼ë¨¹ì—ˆëŠ”ë° ì ìˆ˜ê°€ ë” ë†’ì•„ìš”"ë¼ëŠ” í•œ ì¤„ì˜ ì‚¬ìš©ì í”¼ë“œë°±ì—ì„œ ì‹œì‘ëœ ë¬¸ì œ í•´ê²° ê³¼ì •ì€, í‘œë©´ì ì¸ ë²„ê·¸ ìˆ˜ì •ì„ ë„˜ì–´ **ìŒì„±í•™ ì´ë¡ **, **í†µê³„ì  ë¶„ì„**, **ì‚¬ìš©ì ê²½í—˜ ì„¤ê³„**ê°€ ìœµí•©ëœ ì¢…í•©ì  ì†”ë£¨ì…˜ìœ¼ë¡œ ë°œì „í–ˆìŠµë‹ˆë‹¤.

íŠ¹íˆ GPU ë¹„ìš© ë¬¸ì œë¡œ ì¸í•œ **Whisper.cpp ì „í™˜ ê²°ì •**ì€ ë‹¨ìˆœí•œ ê¸°ìˆ  ì„ íƒì´ ì•„ë‹ˆë¼, **ì„±ëŠ¥ê³¼ ë¹„ìš© íš¨ìœ¨ì„±**ì„ ë™ì‹œì— ë‹¬ì„±í•˜ê¸° ìœ„í•œ ì „ëµì  ì‚¬ê³ ì˜ ê²°ê³¼ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ AI ì‹œìŠ¤í…œì„ ìš´ì˜í•  ë•Œ ë§ˆì£¼í•˜ê²Œ ë˜ëŠ” í˜„ì‹¤ì  ì œì•½ ì¡°ê±´ë“¤ì„ ì°½ì˜ì ìœ¼ë¡œ í•´ê²°í•œ ì‚¬ë¡€ì…ë‹ˆë‹¤.

**ì´ ê°œë°œ ê¸°ê°„ 28ì¼, ì²˜ë¦¬ ì‹œê°„ 75% ë‹¨ì¶•, ì •í™•ë„ 2ë°° í–¥ìƒ, ë¹„ìš© 92% ì ˆì•½**ì´ë¼ëŠ” ì •ëŸ‰ì  ì„±ê³¼ ë’¤ì—ëŠ”, ì‚¬ìš©ì ì¤‘ì‹¬ì˜ ì„¤ê³„ ì‚¬ê³ ì™€ ì§€ì†ì  ê°œì„  ì˜ì§€, ê·¸ë¦¬ê³  ìµœì‹  AI/ML ê¸°ìˆ ì„ ì‹¤ìš©ì ìœ¼ë¡œ ì ìš©í•˜ëŠ” ì—”ì§€ë‹ˆì–´ë§ ì—­ëŸ‰ì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.

**ì´ 21,456ì**