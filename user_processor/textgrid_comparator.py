"""
TextGrid ë¹„êµ ë¶„ì„ ëª¨ë“ˆ (textgrid_comparator.py)

ê¸°ëŠ¥:
- ê¸°ì¤€ ì˜ìƒê³¼ ì‚¬ìš©ì ìŒì„±ì˜ TextGrid ë¹„êµ
- í”¼ì¹˜ íŒ¨í„´ ìœ ì‚¬ë„ ë¶„ì„
- ìŒì†Œ ë‹¨ìœ„ ë°œìŒ ì •í™•ë„ ì¸¡ì •
- íƒ€ì´ë° ì •í™•ë„ ë¶„ì„

ì…ë ¥:
- ê¸°ì¤€ TextGrid íŒŒì¼
- ì‚¬ìš©ì TextGrid íŒŒì¼
- ê¸°ì¤€/ì‚¬ìš©ì ìŒì„± íŒŒì¼ (í”¼ì¹˜ ë¶„ì„ìš©)

ì¶œë ¥: ì¢…í•© ë¹„êµ ê²°ê³¼ JSON
"""

import json
import sys
import os
from pathlib import Path
import numpy as np

# voice_to_pitch ëª¨ë“ˆ import
from voice_to_pitch import create_user_pitch_json, load_pitch_data, extract_pitch_segment

# textgrid ë° í”¼ì¹˜ ìœ ì‚¬ë„ ë¶„ì„ ë³‘ë ¬ ì‹¤í–‰ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from concurrent.futures import ThreadPoolExecutor

def parse_textgrid(textgrid_path: str) -> dict:
    """
    TextGrid íŒŒì¼ íŒŒì‹± (ê°„ë‹¨í•œ êµ¬í˜„)
    
    Args:
        textgrid_path: TextGrid íŒŒì¼ ê²½ë¡œ
    
    Returns:
        íŒŒì‹±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    try:
        with open(textgrid_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ê°„ë‹¨í•œ TextGrid íŒŒì‹± (phones tier ì¶”ì¶œ)
        lines = content.split('\n')
        intervals = []
        
        in_phones_tier = False
        current_interval = {}
        
        for line in lines:
            line = line.strip()
            
            if 'name = "phones"' in line:
                in_phones_tier = True
                continue
            
            if in_phones_tier and 'intervals [' in line:
                if current_interval:
                    intervals.append(current_interval)
                current_interval = {}
                continue
            
            if in_phones_tier and 'xmin =' in line:
                current_interval['start'] = float(line.split('=')[1].strip())
            elif in_phones_tier and 'xmax =' in line:
                current_interval['end'] = float(line.split('=')[1].strip())
            elif in_phones_tier and 'text =' in line:
                text = line.split('=')[1].strip().strip('"')
                current_interval['phone'] = text
            
            # ë‹¤ë¥¸ tier ì‹œì‘í•˜ë©´ phones tier ì¢…ë£Œ
            if in_phones_tier and 'name =' in line and 'phones' not in line:
                if current_interval:
                    intervals.append(current_interval)
                break
        
        # ë§ˆì§€ë§‰ interval ì¶”ê°€
        if current_interval:
            intervals.append(current_interval)
        
        return {
            "file": textgrid_path,
            "intervals": intervals,
            "total_duration": intervals[-1]['end'] if intervals else 0
        }
        
    except Exception as e:
        print(f"âŒ TextGrid íŒŒì‹± ì‹¤íŒ¨: {e}")
        return {"file": textgrid_path, "intervals": [], "total_duration": 0}

def compare_textgrids(reference_textgrid: str, user_textgrid: str) -> dict:
    """
    ë‘ TextGrid íŒŒì¼ì„ ë¹„êµí•˜ì—¬ ë°œìŒ ì •í™•ë„ ë¶„ì„
    
    Args:
        reference_textgrid: ê¸°ì¤€ TextGrid íŒŒì¼ ê²½ë¡œ
        user_textgrid: ì‚¬ìš©ì TextGrid íŒŒì¼ ê²½ë¡œ
    
    Returns:
        ìŒì†Œë³„ ë¹„êµ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    #print(f"ğŸ“Š TextGrid ë¹„êµ ë¶„ì„ ì¤‘...")
    
    # TextGrid íŒŒì‹±
    ref_data = parse_textgrid(reference_textgrid)
    user_data = parse_textgrid(user_textgrid)
    
    ref_phones = [interval['phone'] for interval in ref_data['intervals'] if interval.get('phone')]
    user_phones = [interval['phone'] for interval in user_data['intervals'] if interval.get('phone')]
    
    # ë°œìŒ ì •í™•ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë§¤ì¹­)
    total_phones = len(ref_phones)
    matched_phones = 0
    
    min_length = min(len(ref_phones), len(user_phones))
    for i in range(min_length):
        if ref_phones[i] == user_phones[i]:
            matched_phones += 1
    
    pronunciation_accuracy = matched_phones / total_phones if total_phones > 0 else 0
    
    # íƒ€ì´ë° ì •í™•ë„ ê³„ì‚°
    timing_accuracy = calculate_timing_accuracy(ref_data['intervals'], user_data['intervals'])
    
    return {
        "pronunciation_accuracy": round(pronunciation_accuracy, 3),
        "timing_accuracy": round(timing_accuracy, 3),
        "reference_phones": len(ref_phones),
        "user_phones": len(user_phones),
        "matched_phones": matched_phones,
        "reference_duration": ref_data['total_duration'],
        "user_duration": user_data['total_duration']
    }

def calculate_timing_accuracy(ref_intervals: list, user_intervals: list) -> float:
    """
    íƒ€ì´ë° ì •í™•ë„ ê³„ì‚°
    """
    if not ref_intervals or not user_intervals:
        return 0.0
    
    # ì „ì²´ ë°œí™” ì‹œê°„ ë¹„êµ
    ref_duration = ref_intervals[-1]['end'] - ref_intervals[0]['start']
    user_duration = user_intervals[-1]['end'] - user_intervals[0]['start']
    
    # ì‹œê°„ ì°¨ì´ ë¹„ìœ¨ë¡œ ì •í™•ë„ ê³„ì‚°
    time_diff_ratio = abs(ref_duration - user_duration) / ref_duration if ref_duration > 0 else 1
    timing_accuracy = max(0, 1 - time_diff_ratio)
    
    return timing_accuracy

def create_reference_pitch_json(audio_path: str, output_path: str) -> str:
    """
    ê¸°ì¤€ ìŒì„± í”¼ì¹˜ ë°ì´í„° ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
    """
    try:
        import parselmouth
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        # ìŒì„± íŒŒì¼ ë¡œë“œ
        sound = parselmouth.Sound(audio_path)
        
        # í”¼ì¹˜ ì¶”ì¶œ
        pitch = sound.to_pitch(time_step=0.01)
        
        # JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        pitch_data = []
        for i, time in enumerate(pitch.xs()):
            hz_value = pitch.get_value_at_time(time)
            pitch_data.append({
                "time": round(time, 3),
                "hz": round(hz_value, 2) if not np.isnan(hz_value) else None
            })
        
        # íŒŒì¼ ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(pitch_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ê¸°ì¤€ í”¼ì¹˜ ë°ì´í„° ì €ì¥: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"âŒ ê¸°ì¤€ í”¼ì¹˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def extract_pitch_segment_safe(pitch_data: list, start: float, end: float) -> list:
    """ì•ˆì „í•œ í”¼ì¹˜ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ"""
    segment = []
    for p in pitch_data:
        if start <= p["time"] <= end and p["hz"] is not None and p["hz"] > 0:
            segment.append(p["hz"])
    return segment

def calculate_dtw_pitch_similarity(ref_pitch: list, user_pitch: list) -> float:
    """DTW ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ê³ ê¸‰ í”¼ì¹˜ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        from fastdtw import fastdtw
        from scipy.spatial.distance import euclidean
        
        # ìµœì†Œ ê¸¸ì´ í™•ë³´
        if len(ref_pitch) < 3 or len(user_pitch) < 3:
            return 0.0
        
        # Z-score ì •ê·œí™”
        ref_norm = zscore_normalize_pitch(ref_pitch)
        user_norm = zscore_normalize_pitch(user_pitch)
        
        # DTW ê±°ë¦¬ ê³„ì‚°
        distance, _ = fastdtw(ref_norm, user_norm, dist=euclidean)
        
        # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (0~1)
        max_len = max(len(ref_norm), len(user_norm))
        similarity = max(0.0, 1.0 - distance / max_len)
        
        return similarity
        
    except ImportError:
        print("âš ï¸ fastdtw ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return calculate_simple_pitch_similarity(ref_pitch, user_pitch)
    except Exception as e:
        print(f"âš ï¸ DTW í”¼ì¹˜ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return calculate_simple_pitch_similarity(ref_pitch, user_pitch)

def zscore_normalize_pitch(pitch_values: list) -> list:
    """Z-score ì •ê·œí™”"""
    if not pitch_values:
        return []
    
    mean_val = np.mean(pitch_values)
    std_val = np.std(pitch_values)
    
    if std_val == 0:
        return [0.0] * len(pitch_values)
    
    return [(val - mean_val) / std_val for val in pitch_values]

def calculate_simple_pitch_similarity(ref_pitch: list, user_pitch: list) -> float:
    """ê°„ë‹¨í•œ í”¼ì¹˜ ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)"""
    try:
        # ê¸¸ì´ ë§ì¶”ê¸° (ì„ í˜• ë³´ê°„)
        min_len = min(len(ref_pitch), len(user_pitch))
        if min_len < 3:
            return 0.0
        
        # ë¦¬ìƒ˜í”Œë§ìœ¼ë¡œ ê¸¸ì´ ë§ì¶”ê¸°
        ref_resampled = np.interp(np.linspace(0, 1, min_len), 
                                np.linspace(0, 1, len(ref_pitch)), ref_pitch)
        user_resampled = np.interp(np.linspace(0, 1, min_len), 
                                 np.linspace(0, 1, len(user_pitch)), user_pitch)
        
        # Z-score ì •ê·œí™”
        ref_norm = (ref_resampled - np.mean(ref_resampled)) / (np.std(ref_resampled) + 1e-8)
        user_norm = (user_resampled - np.mean(user_resampled)) / (np.std(user_resampled) + 1e-8)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        dot_product = np.dot(ref_norm, user_norm)
        norm_ref = np.linalg.norm(ref_norm)
        norm_user = np.linalg.norm(user_norm)
        
        if norm_ref == 0 or norm_user == 0:
            return 0.0
        
        similarity = dot_product / (norm_ref * norm_user)
        return max(0.0, (similarity + 1) / 2)  # -1~1ì„ 0~1ë¡œ ë³€í™˜
        
    except Exception as e:
        print(f"âš ï¸ í”¼ì¹˜ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0

def comprehensive_analysis(reference_textgrid: str, user_textgrid: str,
                         reference_audio: str, user_audio: str,
                         reference_segments: list) -> dict:
    """
    ì¢…í•© ë¹„êµ ë¶„ì„
    
    Args:
        reference_textgrid: ê¸°ì¤€ TextGrid íŒŒì¼
        user_textgrid: ì‚¬ìš©ì TextGrid íŒŒì¼
        reference_audio: ê¸°ì¤€ ìŒì„± íŒŒì¼
        user_audio: ì‚¬ìš©ì ìŒì„± íŒŒì¼
        reference_segments: ê¸°ì¤€ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´
    
    Returns:
        ì¢…í•© ë¶„ì„ ê²°ê³¼
    """
    print("ğŸ” ì¢…í•© ë¹„êµ ë¶„ì„ ì‹œì‘...")
    
    # 1, 2. textgrid ë¹„êµì™€ í”¼ì¹˜ ë¶„ì„ì„ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì‹œê°„ ë‹¨ì¶•
    print("ğŸ“Š textgrid ë° í”¼ì¹˜ ìœ ì‚¬ë„ ë¹„êµ ë¶„ì„ ì‹œì‘...")

    with ThreadPoolExecutor(max_workers=2) as executor:
        textgrid_future = executor.submit(compare_textgrids, reference_textgrid, user_textgrid)
        pitch_future = executor.submit(analyze_pitch_similarity, reference_audio, user_audio, reference_segments)

        textgrid_results = textgrid_future.result()
        pitch_results = pitch_future.result()
    
    # 3. ì¢…í•© ê²°ê³¼
    comprehensive_result = {
        "textgrid_analysis": textgrid_results,
        "pitch_analysis": pitch_results,
        "overall_scores": {
            "pronunciation_score": textgrid_results.get("pronunciation_accuracy", 0) * 100,
            "timing_score": textgrid_results.get("timing_accuracy", 0) * 100,
            "pitch_score": pitch_results.get("pitch_similarity", 0) * 100
        },
        "file_paths": {
            "reference_textgrid": reference_textgrid,
            "user_textgrid": user_textgrid,
            "reference_audio": reference_audio,
            "user_audio": user_audio
        }
    }
    
    # ê²°ê³¼ ì €ì¥
    shared_data_path = Path("../shared_data")
    result_path = shared_data_path / "comparison_result.json"
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump(comprehensive_result, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ì¢…í•© ë¶„ì„ ì™„ë£Œ: {result_path}")
    return comprehensive_result

def analyze_pitch_similarity(reference_audio: str, user_audio: str, segments: list) -> dict:
    """
    í”¼ì¹˜ ìœ ì‚¬ë„ ë¶„ì„
    """
    #print("ğŸµ í”¼ì¹˜ ìœ ì‚¬ë„ ë¶„ì„ ì¤‘...")
    
    try:
        # í”¼ì¹˜ ë°ì´í„° ìƒì„±
        shared_data_path = Path("../shared_data")
        pitch_data_path = shared_data_path / "pitch_data"
        pitch_data_path.mkdir(exist_ok=True)
        
        ref_pitch_path = pitch_data_path / "reference" / "pitch.json"
        user_pitch_path = pitch_data_path / "user" / "pitch.json"
        segments_path = pitch_data_path / "segments.json"
        
        # ê¸°ì¤€ ìŒì„± í”¼ì¹˜ ìƒì„±
        create_reference_pitch_json(reference_audio, str(ref_pitch_path))
        
        # ì‚¬ìš©ì ìŒì„± í”¼ì¹˜ ìƒì„±
        create_user_pitch_json(user_audio, str(user_pitch_path))
        
        # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì €ì¥
        with open(segments_path, 'w', encoding='utf-8') as f:
            json.dump(segments, f, ensure_ascii=False, indent=2)
        
        # í”¼ì¹˜ ë°ì´í„° ë¡œë“œ
        ref_pitch_data = load_pitch_data(str(ref_pitch_path))
        user_pitch_data = load_pitch_data(str(user_pitch_path))
        
        # ì„¸ê·¸ë¨¼íŠ¸ë³„ ìœ ì‚¬ë„ ê³„ì‚°
        segment_results = []
        similarities = []
        
        for segment in segments:
            start, end = segment["start"], segment["end"]
            
            # ì„¸ê·¸ë¨¼íŠ¸ë³„ í”¼ì¹˜ ì¶”ì¶œ
            ref_segment = extract_pitch_segment_safe(ref_pitch_data, start, end)
            user_segment = extract_pitch_segment_safe(user_pitch_data, start, end)
            
            if len(ref_segment) > 5 and len(user_segment) > 5:  # ìµœì†Œ ê¸¸ì´ í™•ë³´
                # DTW ì•Œê³ ë¦¬ì¦˜ ìš°ì„  ì‹œë„, ì‹¤íŒ¨ ì‹œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                similarity = calculate_dtw_pitch_similarity(ref_segment, user_segment)
            else:
                similarity = None
            
            segment_results.append({
                "text": segment["text"],
                "start": start,
                "end": end,
                "similarity": round(similarity, 3) if similarity is not None else None
            })
            
            if similarity is not None:
                similarities.append(similarity)
        
        # ì „ì²´ ìœ ì‚¬ë„ í‰ê· 
        avg_similarity = sum(similarities) / len(similarities) if similarities else 0
        
        return {
            "pitch_similarity": round(avg_similarity, 3),
            "segment_details": segment_results
        }
        
    except Exception as e:
        print(f"âŒ í”¼ì¹˜ ìœ ì‚¬ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {"pitch_similarity": 0.0, "segment_details": []}
