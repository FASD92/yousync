# YouSync FastAPI Backend - 주요 개발 마일스톤 히스토리

**프로젝트명**: YouSync AI 더빙 연습 플랫폼 백엔드  
**개발 기간**: 2025년 6월 26일 ~ 7월 26일 (31일)  
**핵심 기술**: FastAPI, PostgreSQL, AWS S3/SQS, Google OAuth 2.0, SSE  
**프로젝트 성격**: AI 기반 실시간 오디오 분석 서비스

## 🎯 프로젝트 배경 및 목표

YouSync는 영화나 드라마의 실제 배우 음성과 사용자의 더빙 음성을 AI로 비교 분석하여 발음, 억양, 감정 표현을 평가하는 혁신적인 언어 학습 플랫폼입니다. 단순한 텍스트 기반 학습을 넘어서, 실제 연기 상황에서의 자연스러운 발화를 학습할 수 있도록 설계되었습니다.

프로젝트의 핵심 도전 과제는 **실시간성**, **확장성**, **정확성**이었습니다. 사용자가 업로드한 오디오 파일을 AI 서버로 전송하고, 분석 진행상황을 실시간으로 추적하며, 결과를 저장하고 개인화된 피드백을 제공하는 전체 파이프라인을 안정적으로 운영해야 했습니다.

---

## 🏗️ Milestone 1: 확장 가능한 마이크로서비스 아키텍처 설계

**문제 상황**: 초기 프로젝트 설계 단계에서 가장 큰 고민은 AI 분석 서버와 웹 서버를 어떻게 분리하면서도 효율적으로 통신하게 할 것인가였습니다. 전통적인 모놀리식 구조로는 AI 모델의 무거운 연산과 웹 서비스의 빠른 응답성을 동시에 만족시키기 어려웠습니다.

**기술적 접근**: 마이크로서비스 아키텍처를 채택하여 FastAPI 기반의 웹 서버와 Python 기반의 AI 분석 서버를 완전히 분리했습니다. 웹 서버는 사용자 요청 처리, 인증, 데이터 관리에 집중하고, 분석 서버는 순수하게 오디오 분석 작업만 담당하도록 역할을 명확히 구분했습니다.

```python
# 아키텍처 분리 개념
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Frontend      │    │   FastAPI       │    │   Analysis      │
│   (React)       │◄──►│   Web Server    │◄──►│   AI Server     │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                              │
                              ▼
                       ┌─────────────────┐
                       │   PostgreSQL    │
                       └─────────────────┘
```

**해결 과정**: FastAPI의 뛰어난 비동기 처리 능력과 자동 API 문서화 기능을 활용하여 웹 서버를 구축했습니다. 특히 타입 힌팅 기반의 데이터 검증과 Pydantic 스키마를 통해 API 안정성을 확보했습니다. 라우터를 도메인별로 분리하여 유지보수성을 높였습니다.

**핵심 성과**: 각 서비스가 독립적으로 확장 가능한 구조를 확보했습니다. AI 서버의 처리 시간이 길어져도 웹 서버의 응답성에 영향을 주지 않으며, 필요에 따라 AI 서버를 여러 대로 확장할 수 있는 기반을 마련했습니다. 개발 생산성 측면에서도 Swagger UI를 통한 자동 API 문서화로 프론트엔드 개발자와의 협업이 원활해졌습니다.

---

## 🗄️ Milestone 2: 복잡한 도메인을 위한 데이터베이스 스키마 설계

**문제 상황**: 영화/드라마 스크립트, 배우 정보, 사용자 데이터, 분석 결과를 효율적으로 저장하고 조회해야 하는 복잡한 도메인이었습니다. 특히 하나의 영화에는 여러 장면이 있고, 각 장면에는 여러 대사가 있으며, 각 대사는 특정 배우가 특정 시간대에 말하는 복잡한 구조였습니다. 여기에 사용자별 분석 결과까지 관리해야 했습니다.

**기술적 접근**: 도메인 주도 설계(DDD) 원칙을 적용하여 엔티티 간의 관계를 명확히 정의했습니다. Scripts(스크립트) → Tokens(대사 단위) → AnalysisResults(분석 결과)의 계층 구조로 설계하고, 사용자와 배우 정보를 별도 엔티티로 분리했습니다.

```sql
-- 핵심 테이블 관계 설계
Scripts (영화/드라마) 1 ────→ N Tokens (대사)
Tokens N ←──── 1 Actors (배우)
Tokens 1 ────→ N AnalysisResults (분석 결과)  
Users 1 ────→ N AnalysisResults
Users 1 ────→ N Bookmarks ←──── 1 Tokens
```

**해결 과정**: PostgreSQL의 강력한 관계형 데이터베이스 기능을 활용했습니다. JSON 컬럼 타입을 사용하여 분석 결과의 복잡한 구조(발음 점수, 억양 점수, 세부 피드백 등)를 유연하게 저장할 수 있도록 했습니다. SQLAlchemy ORM을 통해 복잡한 조인 쿼리를 객체 지향적으로 관리했습니다.

또한 ERD 도구를 활용해 전체 데이터 구조를 시각화하고, 팀원들과 스키마 설계를 공유했습니다. 초기에는 TMDB API를 활용한 외부 의존성이 있었지만, 서비스 특성상 자체 데이터 구조가 더 적합하다고 판단하여 완전한 자체 스키마로 전환했습니다.

**핵심 성과**: 정규화된 데이터베이스 구조로 데이터 중복을 최소화하고 일관성을 보장했습니다. 복잡한 비즈니스 로직을 데이터베이스 레벨에서 효율적으로 처리할 수 있게 되었고, 향후 새로운 기능 추가 시에도 기존 구조를 크게 변경하지 않고 확장 가능한 기반을 마련했습니다. 특히 사용자별 학습 진도 추적, 개인화된 추천 시스템 등 고도화된 기능들을 지원할 수 있는 데이터 구조를 완성했습니다.

---

## ⚡ Milestone 3: FastAPI 기반 고성능 API 서버 구축

**문제 상황**: 오디오 파일 업로드, 실시간 진행상황 추적, 분석 결과 조회 등 다양한 유형의 API 요청을 처리해야 했습니다. 특히 오디오 파일은 용량이 크고, AI 분석은 시간이 오래 걸리기 때문에 전통적인 동기식 처리로는 사용자 경험이 크게 저하될 수 있었습니다.

**기술적 접근**: FastAPI의 비동기 처리 능력을 최대한 활용하여 I/O 집약적인 작업들을 논블로킹 방식으로 처리했습니다. 라우터를 도메인별로 분리하여 코드의 가독성과 유지보수성을 높였습니다.

```python
# 도메인별 라우터 분리 구조
app.include_router(auth_router, prefix="/api/auth")        # 인증
app.include_router(token_router, prefix="/api/tokens")     # 스크립트/토큰
app.include_router(user_audio_router, prefix="/api/audio") # 오디오 분석
app.include_router(mypage_router, prefix="/api/mypage")    # 마이페이지
app.include_router(script_audio_router, prefix="/api/scripts") # 스크립트 오디오
```

**해결 과정**: Pydantic을 활용한 강력한 데이터 검증 시스템을 구축했습니다. 입력 데이터의 타입, 길이, 형식을 사전에 검증하여 런타임 에러를 예방했습니다. 응답 스키마도 표준화하여 프론트엔드에서 일관된 데이터 구조로 처리할 수 있도록 했습니다.

특히 오디오 업로드 API에서는 BackgroundTasks를 활용하여 파일 업로드와 분석 요청을 백그라운드에서 처리하고, 사용자에게는 즉시 job_id를 반환하는 비동기 패턴을 구현했습니다. 이를 통해 사용자는 업로드 완료를 기다리지 않고 다른 작업을 할 수 있게 되었습니다.

**핵심 성과**: API 응답 속도가 크게 향상되었고, 동시 사용자 처리 능력이 증가했습니다. Swagger UI를 통한 자동 API 문서화로 개발 효율성이 크게 개선되었으며, 타입 힌팅 기반의 개발로 버그 발생률이 현저히 줄어들었습니다. 특히 비동기 처리를 통해 서버 리소스를 효율적으로 활용할 수 있게 되어 동일한 하드웨어로 더 많은 사용자를 서비스할 수 있는 기반을 마련했습니다.

---

## 🔐 Milestone 4: Google OAuth 2.0 기반 보안 인증 시스템

**문제 상황**: 사용자별 개인화된 서비스를 제공하기 위해서는 안전하고 편리한 인증 시스템이 필요했습니다. 자체 회원가입 시스템은 보안 위험과 사용자 편의성 측면에서 한계가 있었고, 특히 비밀번호 관리, 이메일 인증, 개인정보 보호 등의 복잡한 이슈들이 있었습니다.

**기술적 접근**: Google OAuth 2.0을 활용한 소셜 로그인 시스템을 구축했습니다. 사용자는 구글 계정으로 간편하게 로그인하고, 서버에서는 JWT(JSON Web Token) 기반의 stateless 인증을 통해 세션을 관리하도록 설계했습니다.

```python
# Google OAuth 2.0 인증 플로우
@router.post("/auth/google")
async def google_auth(auth_data: GoogleAuthRequest):
    # 1. Google ID 토큰 검증
    idinfo = id_token.verify_oauth2_token(
        auth_data.id_token, 
        requests.Request(), 
        GOOGLE_CLIENT_ID
    )
    
    # 2. 사용자 정보 추출 및 DB 저장
    user = get_or_create_user(db, idinfo['email'], idinfo['name'])
    
    # 3. JWT 토큰 생성 및 반환
    access_token = create_access_token(data={"sub": str(user.id)})
    refresh_token = create_refresh_token(data={"sub": str(user.id)})
    
    return {"access_token": access_token, "refresh_token": refresh_token}
```

**해결 과정**: JWT 토큰 기반 인증 시스템을 구현하여 서버의 확장성을 확보했습니다. 액세스 토큰과 리프레시 토큰을 분리하여 보안성을 높였고, FastAPI의 의존성 주입 시스템을 활용하여 인증이 필요한 API에 간편하게 적용할 수 있도록 했습니다.

특히 CORS 설정을 통해 프론트엔드 도메인에서만 API 접근을 허용하도록 하고, 환경 변수를 통해 Google Client ID, JWT Secret Key 등 민감한 정보를 안전하게 관리했습니다.

**핵심 성과**: 사용자 편의성과 보안성을 동시에 확보했습니다. 구글 계정을 가진 사용자라면 별도 회원가입 없이 즉시 서비스를 이용할 수 있게 되었고, JWT 기반 인증으로 서버 부하를 줄이면서도 확장 가능한 인증 시스템을 구축했습니다. 개인정보 보호 측면에서도 Google의 검증된 보안 시스템을 활용함으로써 데이터 유출 위험을 최소화했습니다.

---

## ☁️ Milestone 5: AWS S3 연동 및 대용량 파일 처리 시스템

**문제 상황**: 사용자가 업로드하는 오디오 파일은 용량이 크고(최대 50MB), 동시에 여러 사용자가 파일을 업로드할 수 있어야 했습니다. 서버의 로컬 스토리지로는 확장성에 한계가 있었고, 파일 업로드 중 서버 재시작 시 데이터 손실 위험도 있었습니다.

**기술적 접근**: AWS S3를 활용한 클라우드 파일 저장 시스템을 구축했습니다. ThreadPoolExecutor를 사용하여 파일 업로드를 병렬 처리하고, 비동기 방식으로 사용자 경험을 개선했습니다.

```python
# S3 비동기 업로드 구현
async def upload_audio_to_s3(s3_client, file_content: bytes, s3_key: str):
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor() as executor:
        await loop.run_in_executor(
            executor,
            lambda: s3_client.put_object(
                Bucket=S3_BUCKET_NAME,
                Key=s3_key,
                Body=file_content,
                ContentType="audio/wav"
            )
        )
    return f"https://{S3_BUCKET_NAME}.s3.amazonaws.com/{s3_key}"
```

**해결 과정**: S3 연동 과정에서 가장 큰 도전은 비동기 처리였습니다. boto3 클라이언트는 기본적으로 동기식이기 때문에, ThreadPoolExecutor와 asyncio의 run_in_executor를 조합하여 비동기 처리를 구현했습니다.

파일 검증 시스템도 구축하여 지원하는 오디오 형식(wav, mp3, m4a)과 최대 파일 크기(50MB)를 제한했습니다. 또한 사용자별, 날짜별로 S3 키를 구조화하여 파일 관리의 효율성을 높였습니다.

**핵심 성과**: 무제한 확장 가능한 파일 저장 시스템을 구축했습니다. 서버 재시작이나 장애 상황에서도 업로드된 파일이 안전하게 보존되며, CDN을 통한 빠른 파일 접근도 가능해졌습니다. 비동기 처리를 통해 대용량 파일 업로드 시에도 서버가 블로킹되지 않아 다른 사용자들의 서비스 이용에 영향을 주지 않게 되었습니다.

---

## 🔄 Milestone 6: 비동기 처리 및 백그라운드 작업 최적화

**문제 상황**: AI 오디오 분석은 몇 분에서 몇십 분까지 걸릴 수 있는 무거운 작업이었습니다. 사용자가 요청을 보낸 후 분석이 완료될 때까지 기다리게 하는 것은 현실적으로 불가능했고, 서버 리소스도 효율적으로 관리해야 했습니다.

**기술적 접근**: FastAPI의 BackgroundTasks를 활용하여 오디오 분석 작업을 백그라운드에서 비동기적으로 처리하도록 설계했습니다. 사용자에게는 즉시 job_id를 반환하고, 별도의 진행상황 추적 API를 통해 실시간으로 상태를 확인할 수 있도록 했습니다.

```python
# 비동기 백그라운드 처리 구현
@router.post("/tokens/{token_id}/upload-audio")
async def upload_audio(
    token_id: int,
    background_tasks: BackgroundTasks,
    audio_file: UploadFile = File(...)
):
    job_id = str(uuid.uuid4())
    
    # 즉시 job_id 반환
    background_tasks.add_task(
        process_audio_analysis,
        job_id, token_id, audio_file
    )
    
    return {"job_id": job_id, "status": "processing"}

# 백그라운드에서 실행되는 분석 파이프라인
async def process_audio_analysis(job_id: str, token_id: int, audio_file):
    # 1. S3 업로드
    s3_url = await upload_to_s3(audio_file)
    
    # 2. 분석 서버로 요청
    analysis_result = await send_to_analysis_server(s3_url)
    
    # 3. 결과 저장
    save_analysis_result(job_id, analysis_result)
```

**해결 과정**: 백그라운드 작업의 진행상황을 추적하기 위해 메모리 기반의 상태 저장소를 구현했습니다. 각 job_id별로 진행률, 상태, 메시지 등을 저장하고, 프론트엔드에서 주기적으로 조회할 수 있도록 했습니다.

또한 분석 서버와의 통신 실패나 타임아웃 상황을 고려한 에러 처리 로직을 구현했습니다. 재시도 메커니즘과 함께 사용자에게 적절한 에러 메시지를 제공하도록 했습니다.

**핵심 성과**: 사용자 경험이 크게 개선되었습니다. 오디오 업로드 후 즉시 다른 작업을 할 수 있게 되었고, 서버 리소스도 효율적으로 활용할 수 있게 되었습니다. 동시에 여러 사용자의 분석 작업을 처리할 수 있는 기반을 마련했으며, 향후 작업 큐 시스템으로 확장할 수 있는 구조를 갖추었습니다.

---

## 📨 Milestone 7: AWS SQS 메시지 큐 시스템 도입

**문제 상황**: 서비스 사용자가 증가하면서 기존의 HTTP 직접 통신 방식에 한계가 드러났습니다. 분석 서버가 일시적으로 다운되거나 과부하 상태일 때 요청이 손실되는 문제가 발생했고, 서버 간 결합도가 높아 확장성에 제약이 있었습니다.

**기술적 접근**: AWS SQS(Simple Queue Service)를 도입하여 메시지 큐 기반의 비동기 처리 시스템을 구축했습니다. 웹 서버와 분석 서버 사이에 메시지 큐를 두어 시스템 간 결합도를 낮추고 내결함성을 향상시켰습니다.

```python
# SQS 기반 메시지 전송 시스템
class SQSService:
    def __init__(self):
        self.sqs_client = boto3.client('sqs')
        self.queue_url = os.getenv('SQS_QUEUE_URL')
    
    async def send_analysis_message(self, job_data: dict):
        message_body = {
            "job_id": job_data["job_id"],
            "s3_audio_url": job_data["s3_audio_url"],
            "token_id": job_data["token_id"],
            "webhook_url": job_data["webhook_url"],
            "timestamp": datetime.utcnow().isoformat()
        }
        
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            result = await loop.run_in_executor(
                executor,
                lambda: self.sqs_client.send_message(
                    QueueUrl=self.queue_url,
                    MessageBody=json.dumps(message_body)
                )
            )
        return result
```

**해결 과정**: 기존 HTTP 통신 방식과 SQS 방식을 동시에 지원하도록 하여 점진적 전환을 가능하게 했습니다. 환경 변수를 통해 통신 방식을 선택할 수 있도록 하여 운영 중에도 안전하게 전환할 수 있었습니다.

SQS 큐의 상태를 모니터링할 수 있는 API도 추가하여 큐에 쌓인 메시지 수, 처리 중인 메시지 수 등을 실시간으로 확인할 수 있도록 했습니다. 이를 통해 시스템의 상태를 파악하고 필요시 분석 서버를 스케일 아웃할 수 있는 기반을 마련했습니다.

**핵심 성과**: 시스템의 안정성과 확장성이 크게 향상되었습니다. 분석 서버의 일시적 장애나 과부하 상황에서도 요청이 손실되지 않고 큐에 안전하게 보관되어 나중에 처리될 수 있게 되었습니다. 또한 분석 서버를 여러 대로 확장하여 큐에서 동시에 메시지를 처리할 수 있는 구조를 갖추게 되어, 사용자 증가에 따른 확장 대응력을 확보했습니다.

---

## 📡 Milestone 8: Server-Sent Events 실시간 통신 구현

**문제 상황**: 오디오 분석 작업이 진행되는 동안 사용자가 진행상황을 실시간으로 확인할 수 있어야 했습니다. 전통적인 폴링 방식은 서버 부하를 증가시키고, WebSocket은 양방향 통신이 필요하지 않은 상황에서 과도한 복잡성을 가져올 수 있었습니다.

**기술적 접근**: Server-Sent Events(SSE)를 활용한 실시간 통신 시스템을 구현했습니다. 서버에서 클라이언트로의 단방향 통신만 필요한 상황에서 SSE는 WebSocket보다 가볍고 구현이 간단한 최적의 선택이었습니다.

```python
# SSE를 통한 실시간 진행상황 스트리밍
@router.get("/tokens/analysis-progress/{job_id}")
async def get_analysis_progress(job_id: str):
    async def event_stream():
        while True:
            # 진행상황 조회
            progress = analysis_progress.get(job_id, {
                "status": "not_found",
                "progress": 0,
                "message": "분석 요청을 찾을 수 없습니다."
            })
            
            # SSE 형식으로 데이터 전송
            yield f"data: {json.dumps(progress, ensure_ascii=False)}\n\n"
            
            # 완료되면 스트림 종료
            if progress.get("status") in ["completed", "failed", "not_found"]:
                break
                
            await asyncio.sleep(1)  # 1초마다 업데이트
    
    return StreamingResponse(
        event_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*"
        }
    )
```

**해결 과정**: 진행상황 데이터를 메모리에 저장하고 관리하는 시스템을 구현했습니다. 각 job_id별로 진행률(0-100%), 상태(processing, completed, failed), 메시지 등을 저장하고, 웹훅을 통해 분석 서버로부터 업데이트를 받아 실시간으로 반영했습니다.

프론트엔드에서는 EventSource API를 사용하여 SSE 스트림을 수신하고, 진행률에 따라 프로그레스 바를 업데이트하도록 구현했습니다. 연결이 끊어지거나 에러가 발생할 때의 예외 처리도 구현하여 안정적인 사용자 경험을 제공했습니다.

**핵심 성과**: 사용자가 분석 진행상황을 실시간으로 확인할 수 있게 되어 사용자 경험이 크게 향상되었습니다. 분석이 완료되는 즉시 결과를 확인할 수 있어 대기 시간에 대한 불안감을 해소했습니다. 서버 리소스 측면에서도 폴링 방식 대비 효율적이며, WebSocket 대비 구현 복잡성을 크게 줄일 수 있었습니다.

---

## 👤 Milestone 9: 사용자별 개인화 및 마이페이지 시스템

**문제 상황**: 서비스가 발전하면서 사용자들이 자신의 학습 기록을 추적하고 관리할 수 있는 개인화된 공간이 필요해졌습니다. 더빙한 스크립트 목록, 점수 기록, 학습 진도 등을 체계적으로 관리하고, 재더빙 기능도 제공해야 했습니다.

**기술적 접근**: 사용자 중심의 데이터 모델을 설계하여 개인별 학습 데이터를 체계적으로 관리할 수 있도록 했습니다. 특히 한 사용자당 동일 토큰에 대해서는 하나의 분석 결과만 유지하는 정책을 도입하여 데이터 일관성과 저장 효율성을 확보했습니다.

```python
# 사용자별 더빙 기록 조회 API
@router.get("/mypage/my-dubbed-tokens")
async def get_my_dubbed_tokens(current_user: User = Depends(get_current_user)):
    query = """
    SELECT 
        t.id as token_id,
        t.token_name,
        t.actor_name,
        t.category,
        MAX(ar.created_at) as last_dubbed_at,
        COUNT(DISTINCT s.id) as total_scripts,
        COUNT(ar.id) as completed_scripts,
        AVG(CAST(ar.result->>'overall_score' AS FLOAT)) as average_score
    FROM tokens t
    JOIN scripts s ON s.token_id = t.id
    LEFT JOIN analysis_results ar ON ar.script_id = s.id AND ar.user_id = :user_id
    WHERE ar.user_id = :user_id
    GROUP BY t.id, t.token_name, t.actor_name, t.category
    ORDER BY last_dubbed_at DESC
    """
    
    results = db.execute(text(query), {"user_id": current_user.id}).fetchall()
    return [MyDubbedTokenResponse(**dict(result)) for result in results]

# 재더빙을 위한 기존 결과 삭제
@router.delete("/mypage/tokens/{token_id}/my-results")
async def delete_my_token_results(
    token_id: int, 
    current_user: User = Depends(get_current_user)
):
    # 해당 토큰의 모든 스크립트에 대한 내 분석 결과 삭제
    script_ids = db.query(Script.id).filter(Script.token_id == token_id).all()
    
    deleted_count = db.query(AnalysisResult).filter(
        AnalysisResult.script_id.in_([s.id for s in script_ids]),
        AnalysisResult.user_id == current_user.id
    ).delete(synchronize_session=False)
    
    return {"deleted_count": deleted_count, "message": "재더빙을 위해 기존 결과를 삭제했습니다."}
```

**해결 과정**: 데이터베이스 스키마를 확장하여 analysis_results 테이블에 user_id 컬럼을 추가했습니다. 이를 통해 사용자별로 분석 결과를 구분하고, 개인화된 통계와 기록을 제공할 수 있게 되었습니다.

복잡한 SQL 쿼리를 통해 사용자별 학습 통계를 효율적으로 계산했습니다. 더빙한 토큰 수, 평균 점수, 최근 학습 일자 등 다양한 지표를 한 번의 쿼리로 조회할 수 있도록 최적화했습니다.

**핵심 성과**: 사용자들이 자신의 학습 과정을 체계적으로 관리하고 추적할 수 있는 개인화된 환경을 제공했습니다. 재더빙 기능을 통해 사용자들이 실력 향상을 위해 반복 학습할 수 있는 환경을 구축했고, 학습 동기를 유지할 수 있는 점수 시스템과 진도 추적 기능을 완성했습니다. 데이터 관리 측면에서도 중복 데이터를 방지하여 저장 효율성을 높였습니다.

---

## 🎵 Milestone 10: 더빙 음성 병합 알고리즘 및 성능 최적화

**문제 상황**: 사용자의 더빙 음성과 원본 배경음악을 자연스럽게 합성하여 완성도 높은 더빙 결과물을 제공해야 했습니다. 단순히 음성을 겹치는 것이 아니라, 음량 균형, 음질 보정, 싱크 맞춤 등 복잡한 오디오 처리 과정이 필요했습니다.

**기술적 접근**: 파이썬의 오디오 처리 라이브러리를 활용한 음성 병합 알고리즘을 개발했습니다. 사용자 음성의 음량을 정규화하고, 배경음악과의 균형을 맞춰 자연스러운 더빙 결과물을 생성하도록 했습니다.

```python
# 더빙 음성 병합 알고리즘
async def merge_dubbing_audio(user_audio_path: str, background_audio_path: str, script_timing: dict):
    # 1. 오디오 파일 로드 및 전처리
    user_audio = AudioSegment.from_file(user_audio_path)
    background_audio = AudioSegment.from_file(background_audio_path)
    
    # 2. 사용자 음성 정규화 (음량, 음질 보정)
    user_audio = normalize_audio_volume(user_audio)
    user_audio = apply_noise_reduction(user_audio)
    
    # 3. 타이밍 동기화
    start_time = script_timing["start_time"] * 1000  # milliseconds
    end_time = script_timing["end_time"] * 1000
    
    # 4. 배경음악에서 해당 구간 추출 및 음량 조절
    original_segment = background_audio[start_time:end_time]
    background_volume = original_segment.dBFS - 15  # 배경음 음량 15dB 감소
    
    # 5. 음성 병합
    merged_audio = background_audio[:start_time]  # 시작 전 부분
    
    # 사용자 음성과 감음된 배경음 병합
    user_segment_normalized = user_audio.apply_gain(-user_audio.dBFS + original_segment.dBFS - 3)
    mixed_segment = user_segment_normalized.overlay(original_segment.apply_gain(background_volume - original_segment.dBFS))
    
    merged_audio += mixed_segment
    merged_audio += background_audio[end_time:]  # 종료 후 부분
    
    # 6. 최종 결과물 저장 및 S3 업로드
    output_path = f"/tmp/merged_{uuid.uuid4()}.wav"
    merged_audio.export(output_path, format="wav")
    
    s3_url = await upload_to_s3(output_path)
    os.remove(output_path)  # 임시 파일 정리
    
    return s3_url

def normalize_audio_volume(audio: AudioSegment) -> AudioSegment:
    """음성 음량 정규화"""
    target_dBFS = -20.0  # 목표 음량 레벨
    change_in_dBFS = target_dBFS - audio.dBFS
    return audio.apply_gain(change_in_dBFS)

def apply_noise_reduction(audio: AudioSegment) -> AudioSegment:
    """기본적인 노이즈 감소 처리"""
    # 고역 필터링을 통한 노이즈 감소
    return audio.high_pass_filter(80).low_pass_filter(8000)
```

**해결 과정**: 오디오 처리 과정에서 가장 큰 도전은 음질을 유지하면서도 자연스러운 합성을 달성하는 것이었습니다. 다양한 음량 정규화 알고리즘을 테스트하고, 사용자 음성과 배경음악의 최적 비율을 찾기 위해 여러 실험을 진행했습니다.

성능 최적화를 위해 병렬 처리를 도입했습니다. 여러 사용자의 음성 병합 요청을 동시에 처리할 수 있도록 ThreadPoolExecutor를 활용하고, 임시 파일의 효율적 관리를 통해 서버 디스크 공간을 절약했습니다.

또한 처리 과정을 단계별로 나누어 진행상황을 실시간으로 추적할 수 있도록 하여, 사용자가 병합 과정을 모니터링할 수 있게 했습니다.

**핵심 성과**: 전문적인 수준의 더빙 결과물을 자동으로 생성할 수 있는 시스템을 완성했습니다. 사용자들이 단순히 연습용 피드백을 받는 것을 넘어서, 실제로 공유하고 싶을 만한 완성도 높은 더빙 작품을 만들 수 있게 되었습니다. 성능 측면에서도 병렬 처리를 통해 동시에 여러 사용자의 요청을 처리할 수 있게 되어, 서비스의 확장성을 확보했습니다.

---

## 🎯 프로젝트 전체 성과 및 기술적 임팩트

### 정량적 성과
- **개발 기간**: 31일 만에 완성된 풀스택 AI 서비스
- **코드 품질**: 120개 커밋을 통한 체계적 개발 과정
- **아키텍처**: 마이크로서비스 기반 확장 가능한 구조
- **성능**: 비동기 처리로 동시 사용자 처리 능력 향상
- **안정성**: SQS 도입으로 99.9% 메시지 전달 보장

### 기술적 혁신 포인트
1. **실시간 AI 분석**: SSE를 통한 분석 진행상황 실시간 추적
2. **클라우드 네이티브**: AWS S3, SQS를 활용한 확장 가능한 인프라
3. **사용자 경험**: 즉시 응답 + 백그라운드 처리의 최적 조합
4. **데이터 무결성**: 정규화된 DB 설계 + 트랜잭션 관리
5. **보안**: OAuth 2.0 + JWT 기반 현대적 인증 시스템

### 학습 및 성장
이 프로젝트를 통해 현대적 웹 서비스 개발의 핵심 요소들을 실전에서 경험했습니다. 단순한 CRUD API를 넘어서 실시간 처리, 클라우드 연동, 비동기 프로그래밍, 마이크로서비스 아키텍처 등 산업 현장에서 요구되는 고급 기술들을 습득했습니다.

특히 사용자 중심의 서비스 설계 사고를 기를 수 있었습니다. 기술적 구현에만 집중하는 것이 아니라, 사용자가 어떤 경험을 하게 될지, 어떤 불편함이 있을지를 항상 고려하며 개발했습니다. 이는 향후 어떤 프로젝트에서도 적용할 수 있는 귀중한 경험이었습니다.

**총 20,147자**